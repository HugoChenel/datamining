```
Identification et Classification de systÃ¨mes ABC
```



Dans le cadre de lâ€™UE â€œFouille de donnÃ©esâ€ par R. Barriot 

CHENEL Hugo

GHEZIEL Nadine 

 

M1 â€œBiologie Informatique et Biologie des SystÃ¨mesâ€


[TOC]


 	 	

**CONTEXTE**

Lâ€™objectif de ce projet consiste en la mise en place dâ€™une mÃ©thode permettant lâ€™annotation de gÃ©nomes complets de procaryotes en termes de systÃ¨mes ABC.

Les systÃ¨mes ABC (ATP Binding Cassette) constituent un large ensemble de protÃ©ines transmembranaires. Leur rÃ´le est de transporter unidirectionnellement divers substrats Ã  travers la membrane cytoplasmique. Lâ€™hydrolyse de lâ€™ATP est nÃ©cessaire comme source dâ€™Ã©nergie pour le transport. La libÃ©ration dâ€™un groupement phosphate et dâ€™ADP est gÃ©nÃ©rÃ©e: il sâ€™agit dâ€™un transport actif primaire.

Ces systÃ¨mes formant une trÃ¨s grande famille multigÃ©nique sont retrouvÃ©s dans les 3 rÃ¨gnes du vivant (eucaryotes, archÃ©es et procaryotes). Chez ces derniers, ils sont la plupart du temps impliquÃ©s dans l'efflux de molÃ©cules toxiques comme les antibiotiques.

Lâ€™<span style="text-decoration:underline;">architecture des transporteurs est conservÃ©e</span> au sein de la majoritÃ© de ces systÃ¨mes. Cependant, leur <span style="text-decoration:underline;">organisation en domaine est variable</span>. On observe gÃ©nÃ©ralement 2 domaines pour les exportateurs et 3 domaines pour les importeurs :

- MSD : Membrane Spanning Domain. 2 domaines MSD (hÃ©tÃ©ro ou homo-dimÃ¨re) forment le pore Ã  travers la membrane.

- NBD : Nucleotide Binding Domain. 2 domaines (hÃ©tÃ©ro ou homo-dimÃ¨re) fournissent lâ€™Ã©nergie pour le transport actif par hydrolyse de lâ€™ATP.

- SBP : Solute Binding Protein. 1 domaine capture le substrat et lâ€™amÃ¨ne Ã  lâ€™entrÃ©e du pore.

De plus, certains domaines peuvent Ãªtre portÃ©s par un mÃªme gÃ¨ne ou des gÃ¨nes diffÃ©rents, mais on peut Ã©galement retrouver un seul gÃ¨ne pour plusieurs domaines.



<p id="gdcalert1" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/image1.png). Store image on your image server and adjust path/filename/extension if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert2">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/image1.png "image_tooltip")


**Fig.1 : **Architecture des transporteurs ABC [http://silico.biotoul.fr/enseignement/m1/datamining/projet/sujet.html](http://silico.biotoul.fr/enseignement/m1/datamining/projet/sujet.html)

Par exemple : 



*   MSD-MSD : un gÃ¨ne contient 2 domaines MSD
*   MSD-NBD : un gÃ¨ne arbore un domaine MSD suivi dâ€™un domaine NBD

De plus, la structure peut Ãªtre homodimÃ©rique (2 protÃ©ines codÃ©es par le mÃªme gÃ¨ne) ou hÃ©tÃ©rodimÃ©rique (2 protÃ©ines codÃ©es par 2 gÃ¨nes diffÃ©rents). 	

Ces systÃ¨mes Ã©tant trÃ¨s anciens, ils se sont fortement diversifiÃ©s au cours de lâ€™Ã©volution avec lâ€™accumulation de mutations sur la sÃ©quence de leurs gÃ¨nes. A la suite dâ€™analyses de similaritÃ© de sÃ©quence**,** il a Ã©tÃ© possible de les classer en une vingtaine de sous-familles dÃ©terminÃ©es. Cette similaritÃ© de sÃ©quence indique que les molÃ©cules transportÃ©es sont similaires (cela nâ€™est pas transposable Ã  toutes les familles multigÃ©niques). Une seule mutation peut suffire Ã  modifier complÃ¨tement la fonction.

Les techniques de sÃ©quenÃ§age gÃ©nomique ont progressÃ© ces derniÃ¨res annÃ©es, permettant dâ€™obtenir les sÃ©quences gÃ©nomiques complÃ¨tes de diffÃ©rents organismes. La gÃ©nomique produit des volumes consÃ©quents de donnÃ©es.                              

Lâ€™annotation des gÃ©nomes permet de trier et organiser ces donnÃ©es afin de leur donner du sens. Il pourrait Ãªtre judicieux dâ€™utiliser les donnÃ©es disponibles relatives aux systÃ¨mes ABC afin dâ€™annoter automatiquement les informations liÃ©es aux systÃ¨mes ABC dâ€™un gÃ©nome.

**OBJECTIFS 	 	**

Le data mining, ou Knowledge Discovery in Databases (KDD), est un processus permettant lâ€™extraction des connaissances intÃ©ressantes ou des motifs/patterns Ã  partir dâ€™une grande quantitÃ© de donnÃ©es. Composante essentielle des techniques d'analyse des grands jeux de donnÃ©es, cette technique permet lâ€™exploration et lâ€™analyse de donnÃ©es volumineuses, la transformation de ces donnÃ©es en information utile, et Ã©ventuellement la recherche de relation entre les donnÃ©es.

En dâ€™autres termes, le data mining consiste en la dÃ©couverte de connaissances dans les bases de donnÃ©es.

Fig. 2 : Processus dâ€™extraction de connaissances Ã  partir de bases de donnÃ©es

[https://touriaelouahabi.wordpress.com/ecbd/concepts-et-principes-du-data-mining/](https://touriaelouahabi.wordpress.com/ecbd/concepts-et-principes-du-data-mining/)

<span style="text-decoration:underline;">	 	 	 	</span>

Une succession dâ€™Ã©tapes est impliquÃ©e dans le processus de dÃ©couverte de connaissances:



*   sÃ©lection des donnÃ©es Ã  lâ€™aide de la crÃ©ation du jeu de donnÃ©es cible (intÃ©gration)
*   nettoyage et prÃ©traitement des donnÃ©es
*   rÃ©duction et transformation des donnÃ©es (normalisation)
*   choix des fonctionnalitÃ©s  de data mining et des algorithmes 
*   recherche de motifs intÃ©ressants
*   reprÃ©sentation de connaissances aprÃ¨s Ã©valuation de ces motifs

Cette procÃ©dure aboutit Ã  la dÃ©couverte de connaissances.

Deux types d'apprentissages sont utilisÃ©s en fouille de donnÃ©es : 

-Le premier est un <span style="text-decoration:underline;">apprentissage non supervisÃ©</span>, les classes sont alors inconnues. Lâ€™objectif est de, Ã  partir de n observations, constituer k groupes tels que ces groupes soient constituÃ©s dâ€™observations semblables, mais quâ€™ils soient le plus diffÃ©rents possibles entre eux.  On parle de <span style="text-decoration:underline;">clustering</span>. \
Il existe des mÃ©thodes non hiÃ©rarchiques, dites par partitionnement, qui consiste en la construction de k partitions qui seront corrigÃ©es jusquâ€™Ã  obtenir une similaritÃ© parfaite. Lâ€™exemple le plus connu est la mÃ©thode du k-means. \
Les mÃ©thodes hiÃ©rarchiques consistent en la crÃ©ation dâ€™une dÃ©composition hiÃ©rarchique par agglomÃ©ration ou division de groupes similaires ou dissimilaires(ex : Hierarchical clustering).

-Le second est un <span style="text-decoration:underline;">apprentissage supervisÃ©</span> : Ã©tant donnÃ© un ensemble de classes connues, Ã©tablir les Â« meilleures Â» rÃ¨gles de classement, le jeu de donnÃ©es dâ€™apprentissage fournit donc les classes des objets. Ce type dâ€™apprentissage correspond Ã  la <span style="text-decoration:underline;">classification</span>. \
Lâ€™objectif de cet apprentissage est de modÃ©liser la relation entre les observations et la classe dâ€™appartenance, mais Ã©galement dâ€™identifier la classe dâ€™appartenance dâ€™un objet Ã  partir dâ€™un ensemble de descripteurs. De nombreux outils existent, tels que la mÃ©thode des K plus proches voisins, ou celle de lâ€™arbre de dÃ©cision. 

Les arbres de dÃ©cisions sont des outils dâ€™aide Ã  la dÃ©cision :  une procÃ©dure de classification est construite suivant un protocole simple tout en offrant une interprÃ©tabilitÃ© agrÃ©able aux utilisateurs. Les variables discriminantes seront choisies par le logiciel selon une suite de calculs statistiques. 

La mÃ©thode des K plus proches voisins (ou knn pour â€œk-nearest neighborsâ€) se base sur un algorithme dit paresseux : il nâ€™apprend rien pendant la phase dâ€™entraÃ®nement. La prÃ©diction dâ€™une classe se base sur un concept simple : lâ€™algorithme reÃ§oit une nouvelle donnÃ©e et cherche Ã  calculer ses k plus proches voisins (selon une distance euclidienne par exemple). La donnÃ©e reÃ§oit la mÃªme classe que la classe majoritaire de ses k plus proches voisins.

Il existe plusieurs maniÃ¨res dâ€™Ã©valuer un classificateur : 

partitionnement - validation croisÃ©e - bootstrapping \
-Calcul de la spÃ©cificitÃ© : capacitÃ© Ã  ne dÃ©tecter que des vrais positifs \
-Calcul de la sensibilitÃ© : capacitÃ© Ã  dÃ©tecter un maximum de vrais positifs \
-Courbe ROC : graphique des performances du modÃ¨le, vrais positifs en fonction des faux positifs 

-AUC : pour lâ€™aire sous la courbe ROC : entre 0 et 1, câ€™est une valeur qui fournit la capacitÃ© discriminatoire du modÃ¨le.

La classification est le type dâ€™apprentissage retenu pour ce projet afin dâ€™Ã©valuer si des gÃ¨nes codent ou non pour des protÃ©ines partenaires ABC.

**INFORMATIONS DISPONIBLES**

ABCdb est une banque de donnÃ©es publique dÃ©diÃ©e aux transporteurs ABC. Elle a Ã©tÃ© encodÃ©e Ã  partir de gÃ©nomes procaryotes intÃ©gralement sÃ©quencÃ©s. On dispose donc de donnÃ©es sur les gÃ©nomes expertisÃ©s permettant la classification automatique.

Comment dÃ©finir si un gÃ¨ne code ou pas pour un partenaire dâ€™un systÃ¨me ABC ?           

Deux informations sont pertinentes parmi celles Ã  notre disposition :



*   les domaines prÃ©sents sur la sÃ©quence protÃ©ique correspondant au gÃ¨ne Ã  partir de banques de donnÃ©es de domaines
*   lâ€™orthologie de type 1:1 entre les gÃ¨nes des gÃ©nomes expertisÃ©s sachant que lâ€™on connaÃ®t leur architecture en domaine et leur sous-famille.

**ANALYSE**

Fig 3 : SchÃ©ma Base de donnÃ©es

http://silico.biotoul.fr/enseignement/m1/datamining/projet/sujet.html

Dans un premier temps, il est important de choisir les tables jugÃ©es pertinentes Ã  notre analyse. Selon une rÃ©flexion menÃ©e sur notre problÃ©matique, et sur les attributs contenus dans les tables proposÃ©es, nous avons portÃ©s nos choix sur les suivantes : 



*   Gene
*   Protein
*   Conserved_Domain
*   Functional_Domain

Les tables contiennent certains attributs pertinents Ã  notre analyse : Gene_ID et FD_ID nous permettront de faire correspondre nos 4 tables d'intÃ©rÃªts.

**CONCEPTION**

**<span style="text-decoration:underline;">Matrice individus-variables</span>**

Notre matrice individus-variable a Ã©tÃ© construite Ã  partir du logiciel R version 3.04. Le gestionnaire de bases de donnÃ©es utilisÃ© est le serveur MariaDB version 10.5.9. Lâ€™utilisation du serveur depuis R Ã  lâ€™aide de la librairie RMySQL permet dâ€™effectuer des liens entre ces tables grÃ¢ce Ã  des requÃªtes SQL, et ainsi tirer des donnÃ©es pertinentes pour la suite de lâ€™analyse dans le but dâ€™effectuer notre classification.

Gene ID correspondent Ã  nos individus (soient les lignes de la matrice). 

Les variables (attributs) choisis pour mener Ã  bien la classification sont : 



*   Gene_ID depuis Gene
*   FD_ID depuis Functional Domain
*   Length depuis Functional Domain
*   Score_norm depuis Orthology

Dans un premier temps, il sera nÃ©cessaire de crÃ©er une base de donnÃ©es MariaDB contenant la totalitÃ© de nos tables. La crÃ©ation des tables Ã  lâ€™aide de requÃªtes est automatisÃ©e grÃ¢ce Ã  lâ€™utilisation du document â€œcreate.and.populate.fouille.db.sqlâ€ fourni contenant la totalitÃ© des requÃªtes. 

Une fois cette Ã©tape rÃ©alisÃ©e, il faut crÃ©er une connexion Ã  MariaDB depuis le document R Ã  lâ€™aide des informations de connexion et de lâ€™adresse IP de la machine utilisÃ©e :


```
dbh=dbConnect(MySQL(),
           user="guest", 
           password="bioinfo",
           dbname="fouille", 
           host="195.220.42.4")
```


La premiÃ¨re requÃªte permet de rÃ©cupÃ©rer la majoritÃ© des colonnes de notre matrice :


```
query = "SELECT Gene.GENE_ID, Functional_Domain.FD_length, Functional_Domain.FD_ID, Conserved_Domain.e_Value
           FROM Functional_Domain, Conserved_Domain, Gene
           WHERE Functional_Domain.FD_ID = Conserved_Domain.FD_ID 
           AND Conserved_Domain.GENE_ID = Gene.GENE_ID
           AND Gene.Function like 'ABC%'
           AND Conserved_Domain.e_Value < 0.005"
```


La sÃ©lection indique que sont rÃ©cupÃ©rÃ©es :



*   Le Gene_ID depuis la table Gene (soit lâ€™identifiant unique qui permet de rendre unique chaque individu de la matrice) mais Ã©galement de croiser les tables : câ€™est la clÃ© primaire et secondaire. 
*   Length depuis la table Functional Domain (soit la longueur du domaine fonctionnel) 
*   Le FD_ID (identifiant unique du domaine fonctionnel retrouvÃ©) 
*   La e-value depuis Conserved Domain qui permettra de filtrer les doublons 

Les tables Gene et Conserved_Domain se croisent grÃ¢ce au GENE_ID, Conserved_Domain et Functional_Domain grÃ¢ce au FD_ID. Un premier filtre est effectuÃ© sur les e_value &lt; 0.005 pour optimiser les requÃªtes, et dans Gene : le gÃ¨ne qui doit coder pour une protÃ©ine fonctionnelle ABC.

Il est important de retirer les doublons afin que lâ€™analyse soit menÃ©e avec des individus uniques mais Ã©galement afin de faciliter la commande merge qui suivra plus tard. 


```
The_table1 <- df2 %>% group_by(GENE_ID)  %>% filter(e_Value == min(e_Value))
```


The_table1 reÃ§oit notre premiÃ¨re table (df2) rangÃ©e par GENE_ID qui seront filtrÃ©s : si des doublons de GENE_ID sont prÃ©sents, seul lâ€™individu ayant la e_value la plus faible sera conservÃ© dans la matrice afin de garder les rÃ©sultats les plus significatifs possibles.

Dans un second temps, il faut rÃ©cupÃ©rer le score normalisÃ© Ã©galement sÃ©lectionnÃ© pour cette analyse. La table Orthology Ã©tant trÃ¨s lourde (plusieurs millions dâ€™individus), il est important de filtrer les rÃ©sultats dans un but dâ€™efficience du script. 


```
query = "SELECT subject_id, norm_Score
          FROM  Orthology
          WHERE evalue <= 0.00005 AND subject_id IN (SELECT Gene_ID 
                                                  FROM Protein 
                                                  WHERE Type = 'ABC')" 
```


Cette requÃªte permet une sÃ©lection du subject_id (Ã©quivalent au GENE_ID donc qui nous permettra le lien entre les deux tables) et du score_norm d'intÃ©rÃªt pour notre analyse. Les filtres sâ€™effectueront via une e-value stringeante et des types de protÃ©ines uniquement ABC.


```
The_table2 <- dft %>% group_by(subject_id)  %>% filter(norm_Score == max(norm_Score))

colnames(The_table2)[1] <- "GENE_ID"
```


LÃ  encore, il est nÃ©cessaire de retirer les doublons, mais cette fois en ne gardant que les individus dont le score normalisÃ© sera le plus grand.

Enfin, la colonne subject_id sera renommÃ©e en GENE_ID afin de faciliter la requÃªte du merge entre nos deux tables.


```
table =  merge(The_table1, The_table2, by = "GENE_ID", all.x = TRUE, all.y = FALSE)

matrice = na.omit(table)

matrice1 <- matrice1[,-4:-5]
```


Le merge permet de fusionner nos deux tables sur la base du GENE_ID seulement pour les individus prÃ©sents dans la premiÃ¨re table (The_table1). La seconde requÃªte par le na.omit permet de retirer les lignes contenant des NA (not available). 

Nous retirons alors les colonnes correspondant Ã  la e_value et au norm_score qui mâ€™ont permit quâ€™Ã  amÃ©liorer la qualitÃ© du filtrage mais ne figureront pas dans lâ€™analyse KNIME.


```
conserved <- conserved[,-1]
conserved <- conserved[,-2:-4]
conserved <- conserved[,-4:-5]

colnames(conserved)[1] <- "GENE_ID"

matrice2 =  merge(matrice1, conserved, by = "GENE_ID", all.x = TRUE, all.y = FALSE)
```


Nous sÃ©lectionnons ensuite depuis la table conserved_domain les positions start et end des sÃ©quences ainsi que leur Gene_ID renommÃ© en Gene_ID. Le merge permettra dâ€™ajouter Ã  nos sÃ©quences sÃ©lectionnÃ©es qui codent pour les protÃ©ines de type ABC leur sÃ©quences start et end.


```
functional_domains <- functional_domains[,-2:-5]
functional <- functional_domains %>% group_by(FD_ID)  %>% filter(Family_Link !="")
matriceFinal = merge(matrice2, functional, by = "FD_ID")
```


Depuis functional_domains, nous sÃ©lectionnons les sou_ types de familles ABC, soit la colonne Family_link qui nous permettra de construire nos modÃ¨les de classifications. Un filtre est effectuÃ© afin de supprimer les lignes contenant des cases vides (une majoritÃ© de la table). Le merge est alors effectuÃ© avec la prÃ©cÃ©dente matrice retenue. 


```
matriceFinal <- matriceFinal %>% group_by(GENE_ID)
matriceFinal <- matriceFinal[,-1]
write.table(matriceFinal, file="mymatrix.txt", row.names=FALSE, col.names=TRUE, sep = '\t', append = FALSE, quote = FALSE)
```


Les derniÃ¨res Ã©tapes consistent en : 



*   vÃ©rifier lâ€™absence de doublons
*   supprimer la colonne GENE_ID qui ne sera plus utile Ã  lâ€™analyse 
*   Ecrire la matrice dans un fichier de sortie 

Nous obtenons alors la matrice suivante, composÃ©e de 4523 individus :



<p id="gdcalert2" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/image2.png). Store image on your image server and adjust path/filename/extension if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert3">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/image2.png "image_tooltip")


**<span style="text-decoration:underline;">Knime</span>**

Nous allons maintenant utiliser des mÃ©thodes d'apprentissage proposÃ©es par le logiciel KNIME, un logiciel open source permettant la construction de workflow prÃ©cis. Le workflow sera constituÃ© des diffÃ©rentes Ã©tapes nÃ©cessaires Ã  sa rÃ©alisation depuis les lecture et paramÃ©trage des donnÃ©es, Ã  lâ€™analyse et la visualisation des rÃ©sultats 

KNIME propose lâ€™utilisation dâ€™un nombre Ã©tendu de tests statistiques et algorithmes dÃ©diÃ©s Ã  la fouilles de donnÃ©es, nous en utiliserons plusieurs afin dâ€™interprÃ©ter, mais Ã©galement de comparer  les rÃ©sultats obtenus avec plusieurs mÃ©thodes.


#### **Construction du modÃ¨le**



1. <span style="text-decoration:underline;">Decision Tree Learner</span>

La gÃ©nÃ©ration de lâ€™arbre nÃ©cessaire Ã  la classification se fait en deux Ã©tapes :



*   Construction : initialement, les exemples du jeu d'apprentissage se situent Ã  la racine, puis sâ€™effectue une partition rÃ©cursive des exemples en sÃ©lectionnant les attributs.
*   Ã‰lagage permettant dâ€™identifier supprimer des branches correspondant Ã  des exceptions ou du bruit.

Une mesure de qualitÃ© intÃ©ressante est le <span style="text-decoration:underline;">coefficient de Gini</span>. En effet, cette mesure statistique permet dâ€™Ã©tablir la rÃ©partition d'une variable au sein d'une population. Autrement dit, il mesure la dispersion dâ€™une distribution dans la population.

Un piÃ¨ge Ã  Ã©viter dans cette modÃ©lisation est lâ€™overfitting ; une sur-modÃ©lisation du jeu dâ€™apprentissage dont lâ€™arbre gÃ©nÃ©rÃ© risque de trop reflÃ©ter le jeu dâ€™apprentissage. Pour y remÃ©dier, une mÃ©thode permet d'Ã©valuer les sous-arbres Ã  Ã©laguer (pruning) : le principe <span style="text-decoration:underline;">MDL</span> (minimum description length).

	



2. <span style="text-decoration:underline;">Classificateur bayÃ©sien naÃ¯f </span>

Nous sommes dans le cas dâ€™un apprentissage et dâ€™une prÃ©diction probabiliste. Le terme naÃ¯f signifie que les descripteurs sont conditionnellement indÃ©pendants.

La mÃ©thode se construit de la faÃ§on suivante :



*   DÃ©termination dâ€™un ensemble dâ€™apprentissage
*   DÃ©termination des probabilitÃ©s Ã  priori de chaque classe (donnÃ©es dâ€™observation)
*   Application du thÃ©orÃ¨me de Bayes _ğ‘ƒ_(_C_/_ğ‘‹_)=(_ğ‘ƒ_(_ğ‘‹_/_C_)âˆ—_ğ‘ƒ_(_C_))/_ğ‘ƒ(ğ‘‹_) afin dâ€™obtenir la probabilitÃ© Ã  posteriori des classes
*   Choix de la classe la plus probable
3. <span style="text-decoration:underline;">Plus proches voisins</span> ca sert Ã  rien

    Valeurs binaires


    DissimilaritÃ© de valeurs binaires


    Variables nominales


    Variables ordinales


    Normalisation des donnÃ©es -> z-score

4. <span style="text-decoration:underline;">Random forest</span> constitue une extension de des arbres de dÃ©cisions. Un Ã©chantillonnage des attributs est effectuÃ© pour dÃ©corrÃ©ler les arbres construits. Le principal inconvÃ©nient de cette mÃ©thode est la sensibilitÃ© et le sur-apprentissage. De plus, il nâ€™y a pas dâ€™Ã©lagage, le sur-apprentissage est compensÃ© par le Bagging (Bootstrap Aggregating). raf?


#### **Evaluation dâ€™un classificateur : performances** \
 \
Si une classe est peu prÃ©sente dans le jeu de donnÃ©es initial, le partitionnement peut entraÃ®ner la crÃ©ation dâ€™un jeu dâ€™apprentissage et dâ€™un jeu de test dont le nombre de classes sera diffÃ©rent. Pour y remÃ©dier, on utilisera des validations croisÃ©es.

Ces validations croisÃ©es sont intÃ©grÃ©es dans Knime (`"Cross Validation"`). La construction s'effectue de la maniÃ¨re suivante :



*   le noeud X-Partitioner est placÃ© entre le File Reader et le Learner. Son rÃ´le est de diviser le jeu de donnÃ©es en jeu dâ€™apprentissage pour le Learner et en jeu de test pour le Predictor. Nous avons testÃ© diffÃ©rents nombre de validations, les rÃ©sultats suivants pour toutes les mÃ©thodes dâ€™Ã©chantillonnages auront des 10 et 50 Cross Validation.
*   le noeud X-Aggregator situÃ© aprÃ¨s le Predictor permet une confrontation de la classe permet une confrontation de la classe prÃ©dite Ã  la classe connue pour chacun des objets testÃ©s.
*   en fin de Workflow, le noeud Statistics affiche le taux dâ€™erreur moyen de notre modÃ¨le tandis que le noeud Scorer nous apporte des informations complÃ©mentaires tel que le nombre de VP, FP, VN, FN et ainsi la spÃ©cificitÃ© (capacitÃ© Ã  ne dÃ©tecter que des vrais positifs) et la sensibilitÃ© (capacitÃ© Ã  dÃ©tecter un maximum de vrais positifs).

La validation croisÃ©e â€œLeave-one-outâ€ (validation croisÃ©e avec k=s oÃ¹ k reprÃ©sente le nombre de partitions) nâ€™a pas Ã©tÃ© effectuÃ©e car les temps de calculs Ã©taient trop importants, cela est liÃ© Ã  la taille consÃ©quente de la matrice individu x variable.

**RÃ‰SULTATS **



<p id="gdcalert3" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/image3.png). Store image on your image server and adjust path/filename/extension if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert4">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/image3.png "image_tooltip")


Fig 4 : KNIME _workflow_ for Decision Tree model.

Les rÃ©sultats obtenus pour lâ€™arbre de dÃ©cision sont reprÃ©sentÃ©s dans le tableau ci-dessous :


<table>
  <tr>
   <td><em>Sampling method</em>
   </td>
   <td><em>Number of validations</em>
   </td>
   <td><em>Parameters</em>
   </td>
   <td><em>Mean percentage error </em>
   </td>
  </tr>
  <tr>
   <td rowspan="8" ><strong>Linear sampling</strong>
   </td>
   <td rowspan="4" >10
   </td>
   <td>Gain ratio / No pruning
   </td>
   <td>6.520 %
   </td>
  </tr>
  <tr>
   <td>Gain ratio / MDL
   </td>
   <td>6.476 %
   </td>
  </tr>
  <tr>
   <td>Gini index / No pruning
   </td>
   <td>6.507 %
   </td>
  </tr>
  <tr>
   <td>Gini index / MDL
   </td>
   <td>6.485 %
   </td>
  </tr>
  <tr>
   <td rowspan="4" >50
   </td>
   <td>Gain ratio / No pruning
   </td>
   <td>2.985 %
   </td>
  </tr>
  <tr>
   <td>Gain ratio / MDL
   </td>
   <td>3.31 %
   </td>
  </tr>
  <tr>
   <td>Gini index / No pruning
   </td>
   <td>3.034 %
   </td>
  </tr>
  <tr>
   <td>Gini index / MDL
   </td>
   <td>3.311 %
   </td>
  </tr>
</table>



<table>
  <tr>
   <td><em>Sampling method</em>
   </td>
   <td><em>Number of validations</em>
   </td>
   <td><em>Parameters</em>
   </td>
   <td><em>Mean percentage error </em>
   </td>
  </tr>
  <tr>
   <td rowspan="8" ><strong>Random sampling</strong>
   </td>
   <td rowspan="4" >10
   </td>
   <td>Gain ratio / No pruning
   </td>
   <td>0.720 %
   </td>
  </tr>
  <tr>
   <td>Gain ratio / MDL
   </td>
   <td>0.815 %
   </td>
  </tr>
  <tr>
   <td>Gini index / No pruning
   </td>
   <td>0.703 %
   </td>
  </tr>
  <tr>
   <td>Gini index / MDL
   </td>
   <td>0.762 %
   </td>
  </tr>
  <tr>
   <td rowspan="4" >50
   </td>
   <td>Gain ratio / No pruning
   </td>
   <td>0.68 %
   </td>
  </tr>
  <tr>
   <td>Gain ratio / MDL
   </td>
   <td>0.71 %
   </td>
  </tr>
  <tr>
   <td>Gini index / No pruning
   </td>
   <td>0.687 %
   </td>
  </tr>
  <tr>
   <td>Gini index / MDL
   </td>
   <td>0.738 %
   </td>
  </tr>
</table>



<table>
  <tr>
   <td><em>Sampling method</em>
   </td>
   <td><em>Number of validations</em>
   </td>
   <td><em>Parameters</em>
   </td>
   <td><em>Mean percentage error </em>
   </td>
  </tr>
  <tr>
   <td rowspan="8" ><strong>Stratified sampling</strong>
   </td>
   <td rowspan="4" >10
   </td>
   <td>Gain ratio / No pruning
   </td>
   <td>0.687 %
   </td>
  </tr>
  <tr>
   <td>Gain ratio / MDL
   </td>
   <td>0.762 %
   </td>
  </tr>
  <tr>
   <td>Gini index / No pruning
   </td>
   <td>0.676 %
   </td>
  </tr>
  <tr>
   <td>Gini index / MDL
   </td>
   <td>0.747 %
   </td>
  </tr>
  <tr>
   <td rowspan="4" >50
   </td>
   <td>Gain ratio / No pruning
   </td>
   <td><span style="text-decoration:underline;">0.665</span> %
   </td>
  </tr>
  <tr>
   <td>Gain ratio / MDL
   </td>
   <td>0.696 %
   </td>
  </tr>
  <tr>
   <td>Gini index / No pruning
   </td>
   <td>0.676 %
   </td>
  </tr>
  <tr>
   <td>Gini index / MDL
   </td>
   <td>0.705 %
   </td>
  </tr>
</table>




<p id="gdcalert4" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/image4.png). Store image on your image server and adjust path/filename/extension if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert5">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/image4.png "image_tooltip")


Fig 5 : KNIME _workflow_ for **NaÃ¯ve Bayes model**.

Les rÃ©sultats obtenus pour classification _naÃ¯ve_ bayÃ©sienne sont reprÃ©sentÃ©s dans le tableau ci-dessous :


<table>
  <tr>
   <td><em>Sampling method</em>
   </td>
   <td><em>Number of validations</em>
   </td>
   <td><em>Mean percentage error </em>
   </td>
  </tr>
  <tr>
   <td rowspan="2" ><strong>Linear sampling</strong>
   </td>
   <td>10
   </td>
   <td>13.098 %
   </td>
  </tr>
  <tr>
   <td>50
   </td>
   <td>5.402 %
   </td>
  </tr>
</table>



<table>
  <tr>
   <td><em>Sampling method</em>
   </td>
   <td><em>Number of validations</em>
   </td>
   <td><em>Mean percentage error </em>
   </td>
  </tr>
  <tr>
   <td rowspan="2" ><strong>Random sampling</strong>
   </td>
   <td>10
   </td>
   <td>1.316 %
   </td>
  </tr>
  <tr>
   <td>50
   </td>
   <td>1.312 %
   </td>
  </tr>
</table>



<table>
  <tr>
   <td><em>Sampling method</em>
   </td>
   <td><em>Number of validations</em>
   </td>
   <td><em>Mean percentage error </em>
   </td>
  </tr>
  <tr>
   <td rowspan="2" ><strong>Stratified sampling</strong>
   </td>
   <td>10
   </td>
   <td>1.314 %
   </td>
  </tr>
  <tr>
   <td>50
   </td>
   <td>1.309 %
   </td>
  </tr>
</table>


**DISCUSSION**

Lâ€™ensemble des rÃ©sultats est satisfaisant. Lâ€™arbre de dÃ©cision et le classificateur bayÃ©sien semblent Ãªtre des types de classification pertinent pour notre jeu de donnÃ©es. En effet, hormis pour le linear sampling, le taux dâ€™erreur de ces deux types de classification est infÃ©rieur Ã  2% peu importe les paramÃ¨tres sÃ©lectionnÃ©s.

Plusieurs observations :



*   Le random et stratified sampling permettent dâ€™obtenir un taux dâ€™erreur moyen bien infÃ©rieur Ã  celui obtenu Ã  lâ€™aide dâ€™un linear sampling.
*   Plus le nombre de validations est Ã©levÃ©, plus la performance du modÃ¨le est grande.
*   Au niveau des paramÃ¨tres, on ne peut pas dÃ©terminer lâ€™influence du coefficient de Gini sur le taux dâ€™erreur. Toutefois, on peut remarquer que les arbres nâ€™ayant pas subi dâ€™Ã©lagage ont un taux dâ€™erreur plus faible.

Le taux dâ€™erreur moyen le plus faible est obtenu lorsquâ€™on utilise un arbre de dÃ©cision avec un stratified sampling, 50 validations croisÃ©es, gain ratio et no pruning. Le taux dâ€™erreur moyen est alors de 0.665 %.

Afin dâ€™effectuer une classification sur notre jeu de donnÃ©es, lâ€™arbre de dÃ©cision semble Ãªtre une mÃ©thode plus judicieuse que le classificateur bayÃ©sien.

Cela est probablement liÃ© au fait que ce dernier est basÃ© sur un apprentissage probabiliste. Il calcule explicitement les probabilitÃ©s des hypothÃ¨ses. On considÃ¨re une assomption naÃ¯ve qui concerne lâ€™indÃ©pendance des attributs. Cette hypothÃ¨se dâ€™indÃ©pendance rend le calcul possible et, en cas de vÃ©rification, conduit Ã  des classificateurs optimaux.

Cependant, cette hypothÃ¨se dâ€™indÃ©pendance est rarement vÃ©rifiÃ©e. On pourrait Ã©mettre lâ€™hypothÃ¨se de lâ€™existence dâ€™Ã©ventuelles corrÃ©lations entre les attributs de notre jeu de donnÃ©es. Comment rÃ©soudre ce problÃ¨me ? Les rÃ©seaux BayÃ©siens permettent de combiner le raisonnement BayÃ©sien avec la relation causale entre les attributs.

Le nombre de validations croisÃ©es semble avoir un impact significatif sur le taux dâ€™erreur (corrÃ©lation nÃ©gative entre le nombre de validations croisÃ©es et le taux dâ€™erreur). Cela est liÃ© au fait que le jeu de donnÃ©es est divisÃ© en un nombre plus important de partitions, augmentant ainsi la taille du jeu dâ€™apprentissage; un nombre de validation croisÃ©es de 50 permet donc dâ€™obtenir une plus grande prÃ©cision mais augmente les temps de calcul.

Lâ€™Ã©lagage (MDL) a pour but dâ€™augmenter la prÃ©cision pour Ã©viter que lâ€™arbre gÃ©nÃ©rÃ© ne reflÃ¨te trop le jeu dâ€™apprentissage en supprimant les branches pouvant reprÃ©senter des anomalies. NÃ©anmoins, on observe un taux dâ€™erreur plus grand en prÃ©sence dâ€™Ã©lagage. Ceci peut sembler paradoxal Ã  premiÃ¨re vue, on pourrait Ã©mettre lâ€™hypothÃ¨se que lâ€™Ã©lagage supprime des branches nÃ©cessaires Ã  la classification. Lâ€™Ã©lagage pourrait donc Ãªtre intÃ©ressant pour un jeu de donnÃ©es de taille considÃ©rable mais nâ€™est pas adaptÃ© pour le nÃ´tre.

**BILAN ET PERSPECTIVES**

RÃ©sultats significatifs ? Perspectives pour amÃ©liorer lâ€™analyse ?

Ce quâ€™attend Barriot au final : Discussion sur un des arbres obtenus : est-ce que Ã§a nous apprend quelque chose ? quels attributs et/ou valeurs sont importants ?  \


**GESTION DE PROJET**

La gestion de ce projet fut dÃ©terminÃ©e dÃ©but fÃ©vrier selon le diagramme de GANTT suivant : 

Lâ€™apprÃ©hension du sujet et la prise en main des tables fut plus longue que prÃ©vue, les donnÃ©es fournies Ã©tant trÃ¨s nombreuses et le nombre dâ€™individus trÃ¨s variÃ©s entre les tables, Hugo prit donc de lâ€™avance sur la rÃ©daction de lâ€™introduction et du contexte. 

Le choix du sujet sâ€™est fait rapidement aprÃ¨s, mais le choix des attributs et des tables Ã©taient plus arbitraires dans un premier temps, il Ã©tait Ã©vident que la matrice serait rÃ©visÃ©e au fur et Ã  mesure des essais sur KNIME. 

Nous avons choisis de travailler nos matrices Ã  lâ€™aide de requÃªtes SQL avec MariaDB, seulement, lâ€™accessibilitÃ© Ã  notre base de donnÃ©es et au logiciel nous a Ã©tÃ© possible uniquement depuis la P0 sur le campus. La semaine de vacances fin fÃ©vrier nous a permis de rattraper notre retard, mais Ã©galement de prendre de lâ€™avance sur la construction de la premiÃ¨re matrice. Les requÃªtes SQL Ã©taient simples Ã  rÃ©aliser, notre formation Ã©tant solide et rÃ©cente dans ce domaine. La difficultÃ© principale que nous avons rencontrÃ© concerne les diffÃ©rentes maniÃ¨res de merger nos matrices (prÃ©sence de doublons). 

Les retours sur la matrice nous ont pris la majoritÃ© du temps dÃ©diÃ© Ã  ce projet : afin de gagner en efficacitÃ©, un premier binÃ´me rÃ©visait les matrices pendant que lâ€™autre la lanÃ§ait sur KNIME et analysait les rÃ©sultats. MalgrÃ© une organisation se voulant la plus efficace possible, les retours sur la matrice jusquâ€™Ã  donner des rÃ©sultats acceptables nous ont pris plus de 70% du temps accordÃ© au projet. 

La rÃ©daction du projet sâ€™est maintenue tout au long du travail ce qui nous a permis de gagner du temps sur la fin du projet. 

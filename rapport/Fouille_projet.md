[](images/image3.png) {#h.z30wrspzwzej .c41}
======================

+--------------------------------------------------------------------------+
| Identification et Classification de systÃ¨mes Â ABC {#h.6qfwuhosavu5 .c30} |
| =================================================                        |
+--------------------------------------------------------------------------+

Dans le cadre de lâ€™UE â€œFouille de donnÃ©esâ€ par R. Barriot

CHENEL Hugo

GHEZIEL Nadine

Â 

M1 â€œBiologie Informatique et Biologie des SystÃ¨mesâ€

 {#h.4yckwxhbf6fl .c41 .c74}

-   INTRODUCTION

-   Contexte
-   Objectifs du projet
-   Informations disponibles

-   ANALYSE

-   DonnÃ©es fournies
-   Tables

-   Taxonomy, Strain and Chromosome
-   Gene
-   Conserved\_Domain and Functional\_Domain
-   Orthology
-   Protein and Assembly

-   CONCEPTION

-   Matrice individus-variables
-   KnimeÂ 

-   RÃ‰ALISATION, INTERPRÃ‰TATION ET DISCUSSION

-   BILAN ET PERSPECTIVES

-   Gestion du projet

Â Â Â Â Â Â Â Â Â  Â Â Â Â Â Â Â Â 

-   CONTEXTE

Lâ€™objectif de ce projet consiste en la mise en place dâ€™une mÃ©thode
permettant lâ€™annotation de gÃ©nomes complets de procaryotes en termes de
systÃ¨mes ABC.

Les systÃ¨mes ABC (ATP Binding Cassette) constituent un large ensemble de
protÃ©ines transmembranaires. Leur rÃ´le est de transporter
unidirectionnellement divers substrats Ã  travers la membrane
cytoplasmique. Lâ€™hydrolyse de lâ€™ATP est nÃ©cessaire comme source
dâ€™Ã©nergie pour le transport. La libÃ©ration dâ€™un groupement phosphate et
dâ€™ADP est gÃ©nÃ©rÃ©e: il sâ€™agit dâ€™un transport actif primaire.

Ces systÃ¨mes formant une trÃ¨s grande famille multigÃ©nique sont retrouvÃ©s
dans les 3 rÃ¨gnes du vivant (eucaryotes, archÃ©es et procaryotes). Chez
ces derniers, ils sont la plupart du temps impliquÃ©s dans l'efflux de
molÃ©cules toxiques comme les antibiotiques.

Lâ€™architecture des transporteurs est conservÃ©eÂ au sein de la majoritÃ© de
ces systÃ¨mes. Cependant, leur organisation en domaine est variable. On
observe gÃ©nÃ©ralement 2 domaines pour les exportateurs et 3 domaines pour
les importeurs :

- MSD : Membrane Spanning Domain. 2 domaines MSD (hÃ©tÃ©ro ou homo-dimÃ¨re)
forment le pore Ã  travers la membrane.

- NBD : Nucleotide Binding Domain. 2 domaines (hÃ©tÃ©ro ou homo-dimÃ¨re)
fournissent lâ€™Ã©nergie pour le transport actif par hydrolyse de lâ€™ATP.

- SBP : Solute Binding Protein. 1 domaine capture le substrat et lâ€™amÃ¨ne
Ã  lâ€™entrÃ©e du pore.

De plus, certains domaines peuvent Ãªtre portÃ©s par un mÃªme gÃ¨ne ou des
gÃ¨nes diffÃ©rents, mais on peut Ã©galement retrouver un seul gÃ¨ne pour
plusieurs domaines.

![](images/image9.png)

Fig.1 : Architecture des transporteurs ABC
[http://silico.biotoul.fr/enseignement/m1/datamining/projet/sujet.html](https://www.google.com/url?q=http://silico.biotoul.fr/enseignement/m1/datamining/projet/sujet.html&sa=D&source=editors&ust=1620987391536000&usg=AOvVaw3Q1W2EdT9ViT6QvM2qB7A_)

Par exemple :

-   MSD-MSD : un gÃ¨ne contient 2 domaines MSD
-   MSD-NBD : un gÃ¨ne arbore un domaine MSD suivi dâ€™un domaine NBD

De plus, la structure peut Ãªtre homodimÃ©rique (2 protÃ©ines codÃ©es par le
mÃªme gÃ¨ne) ou hÃ©tÃ©rodimÃ©rique (2 protÃ©ines codÃ©es par 2 gÃ¨nes
diffÃ©rents). Â Â Â Â Â Â Â Â 

Ces systÃ¨mes Ã©tant trÃ¨s anciens, ils se sont fortement diversifiÃ©s au
cours de lâ€™Ã©volution avec lâ€™accumulation de mutations sur la sÃ©quence de
leurs gÃ¨nes. A la suite dâ€™analyses de similaritÃ© de sÃ©quence,Â il a Ã©tÃ©
possible de les classer en une vingtaine de sous-familles dÃ©terminÃ©es.
Cette similaritÃ© de sÃ©quence indique que les molÃ©cules transportÃ©es sont
similaires (cela nâ€™est pas transposable Ã  toutes les familles
multigÃ©niques). Une seule mutation peut suffire Ã  modifier complÃ¨tement
la fonction.

Les techniques de sÃ©quenÃ§age gÃ©nomique ont progressÃ© ces derniÃ¨res
annÃ©es, permettant dâ€™obtenir les sÃ©quences gÃ©nomiques complÃ¨tes de
diffÃ©rents organismes. La gÃ©nomique produit des volumes consÃ©quents de
donnÃ©es. Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â 

Lâ€™annotation des gÃ©nomes permet de trier et organiser ces donnÃ©es afin
de leur donner du sens. Il pourrait Ãªtre judicieux dâ€™utiliser les
donnÃ©es disponibles relatives aux systÃ¨mes ABC afin dâ€™annoter
automatiquement les informations liÃ©es aux systÃ¨mes ABC dâ€™un gÃ©nome.

-   OBJECTIFS Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 

Le data mining, ou Knowledge Discovery in Databases (KDD), est un
processus permettant lâ€™extraction des connaissances intÃ©ressantes ou des
motifs/patterns Ã  partir dâ€™une grande quantitÃ© de donnÃ©es. Composante
essentielle des techniques d'analyse des grands jeux de donnÃ©es, cette
technique permet lâ€™exploration et lâ€™analyse de donnÃ©es volumineuses, la
transformation de ces donnÃ©es en information utile, et Ã©ventuellement la
recherche de relation entre les donnÃ©es.

En dâ€™autres termes, le data mining consiste en la dÃ©couverte de
connaissances dans les bases de donnÃ©es.

Fig. 2 : Processus dâ€™extraction de connaissances Ã  partir de bases de
donnÃ©es![](images/image4.png)

[https://touriaelouahabi.wordpress.com/ecbd/concepts-et-principes-du-data-mining/](https://www.google.com/url?q=https://touriaelouahabi.wordpress.com/ecbd/concepts-et-principes-du-data-mining/&sa=D&source=editors&ust=1620987391538000&usg=AOvVaw3_zZexlTeAEzqbX9CoyWLa)Â 

Une succession dâ€™Ã©tapes est impliquÃ©e dans le processus de dÃ©couverte de
connaissances:

-   sÃ©lection des donnÃ©es Ã  lâ€™aide de la crÃ©ation du jeu de donnÃ©es
    cible (intÃ©gration)
-   nettoyage et prÃ©traitement des donnÃ©es
-   rÃ©duction et transformation des donnÃ©es (normalisation)
-   choix des fonctionnalitÃ©s Â de data mining et des algorithmes
-   recherche de motifs intÃ©ressants
-   reprÃ©sentation de connaissances aprÃ¨s Ã©valuation de ces motifs

Cette procÃ©dure aboutit Ã  la dÃ©couverte de connaissances.

Deux types d'apprentissages sont utilisÃ©s en fouille de donnÃ©es :

-Le premier est un apprentissage non supervisÃ©, les classes sont alors
inconnues. Lâ€™objectif est de, Ã  partir de n observations, constituer k
groupes tels que ces groupes soient constituÃ©s dâ€™observations
semblables, mais quâ€™ils soient le plus diffÃ©rents possibles entre eux.
Â On parle de clustering.\
Il existe des mÃ©thodes non hiÃ©rarchiques, dites par partitionnement, qui
consiste en la construction de k partitions qui seront corrigÃ©es jusquâ€™Ã 
obtenir une similaritÃ© parfaite. Lâ€™exemple le plus connu est la mÃ©thode
du k-means.\
Les mÃ©thodes hiÃ©rarchiques consistent en la crÃ©ation dâ€™une dÃ©composition
hiÃ©rarchique par agglomÃ©ration ou division de groupes similaires ou
dissimilaires(ex : Hierarchical clustering).

-Le second est un apprentissage supervisÃ©Â : Ã©tant donnÃ© un ensemble de
classes connues, Ã©tablir les Â« meilleures Â» rÃ¨gles de classement, le jeu
de donnÃ©es dâ€™apprentissage fournit donc les classes des objets. Ce type
dâ€™apprentissage correspond Ã  la classification.\
Lâ€™objectif de cet apprentissage est de modÃ©liser la relation entre les
observations et la classe dâ€™appartenance, mais Ã©galement dâ€™identifier la
classe dâ€™appartenance dâ€™un objet Ã  partir dâ€™un ensemble de descripteurs.
De nombreux outils existent, tels que la mÃ©thode des K plus proches
voisins, ou celle de lâ€™arbre de dÃ©cision.

Les arbres de dÃ©cisions sont des outils dâ€™aide Ã  la dÃ©cision : Â une
procÃ©dure de classification est construite suivant un protocole simple
tout en offrant une interprÃ©tabilitÃ© agrÃ©able aux utilisateurs. Les
variables discriminantes seront choisies par le logiciel selon une suite
de calculs statistiques.

La mÃ©thode des K plus proches voisins (ou knn pour â€œk-nearest
neighborsâ€) se base sur un algorithme dit paresseux : il nâ€™apprend rien
pendant la phase dâ€™entraÃ®nement. La prÃ©diction dâ€™une classe se base sur
un concept simple : lâ€™algorithme reÃ§oit une nouvelle donnÃ©e et cherche Ã 
calculer ses k plus proches voisins (selon une distance euclidienne par
exemple). La donnÃ©e reÃ§oit la mÃªme classe que la classe majoritaire de
ses k plus proches voisins.

Il existe plusieurs maniÃ¨res dâ€™Ã©valuer un classificateur :

La validation croisÃ©e est une mÃ©thode dâ€™estimation de la fiabilitÃ© dâ€™un
modÃ¨le basÃ© sur une technique dâ€™Ã©chantillonnage. Son principe consiste Ã 
diviser les donnÃ©es en k-partitions puis utiliser k-1 partitions pour
lâ€™apprentissage et la derniÃ¨re pour le test. AprÃ¨s l'apprentissage, on
peut calculer une performance de validation.

Divers autres paramÃ¨tres permettent lâ€™Ã©valuation dâ€™un classificateur :\
-Calcul de la spÃ©cificitÃ© : capacitÃ© Ã  ne dÃ©tecter que des vrais
positifs\
-Calcul de la sensibilitÃ© : capacitÃ© Ã  dÃ©tecter un maximum de vrais
positifs\
-Courbe ROC : graphique des performances du modÃ¨le, vrais positifs en
fonction des faux positifs

-AUC : pour lâ€™aire sous la courbe ROC : entre 0 et 1, câ€™est une valeur
qui fournit la capacitÃ© discriminatoire du modÃ¨le.

La classification est le type dâ€™apprentissage retenu pour ce projet afin
de classer les gÃ¨nes selon leur sous-type de protÃ©ine ABC.

-   INFORMATIONS DISPONIBLES

ABCdb est une banque de donnÃ©es publique dÃ©diÃ©e aux transporteurs ABC.
Elle a Ã©tÃ© encodÃ©e Ã  partir de gÃ©nomes procaryotes intÃ©gralement
sÃ©quencÃ©s. On dispose donc de donnÃ©es sur les gÃ©nomes expertisÃ©s
permettant la classification automatique.

Comment dÃ©finir si un gÃ¨ne code ou pas pour un partenaire dâ€™un systÃ¨me
ABC ? Â  Â  Â  Â  Â 

Deux informations sont pertinentes parmi celles Ã  notre disposition :

-   les domaines prÃ©sents sur la sÃ©quence protÃ©ique correspondant au
    gÃ¨ne Ã  partir de banques de donnÃ©es de domaines
-   lâ€™orthologie de type 1:1 entre les gÃ¨nes des gÃ©nomes expertisÃ©s
    sachant que lâ€™on connaÃ®t leur architecture en domaine et leur
    sous-famille.

-   ANALYSE![](images/image7.png)

Fig 3 : SchÃ©ma Base de donnÃ©es

[http://silico.biotoul.fr/enseignement/m1/datamining/projet/sujet.html](https://www.google.com/url?q=http://silico.biotoul.fr/enseignement/m1/datamining/projet/sujet.html&sa=D&source=editors&ust=1620987391541000&usg=AOvVaw0naDXB6Qn2rUMxNJI6gd1v)

Dans un premier temps, il est important de choisir les tables jugÃ©es
pertinentes Ã  notre analyse. Selon une rÃ©flexion menÃ©e sur notre
problÃ©matique, et sur les attributs contenus dans les tables proposÃ©es,
nous avons portÃ©s nos choix sur les suivantes :

-   Gene
-   Protein
-   Conserved\_Domain
-   Functional\_Domain

Les tables contiennent certains attributs pertinents Ã  notre analyse :
Gene\_ID et FD\_ID nous permettront de faire correspondre nos 4 tables
d'intÃ©rÃªts.

-   CONCEPTION

-   Matrice individus-variables

Notre matrice individus-variable a Ã©tÃ© construite Ã  partir du logiciel R
version 3.04. Le gestionnaire de bases de donnÃ©es utilisÃ© est le serveur
MariaDB version 10.5.9. Lâ€™utilisation du serveur depuis R Ã  lâ€™aide de la
librairie RMySQL permet dâ€™effectuer des liens entre ces tables grÃ¢ce Ã 
des requÃªtes SQL, et ainsi tirer des donnÃ©es pertinentes pour la suite
de lâ€™analyse dans le but dâ€™effectuer notre classification.

Gene ID correspondent Ã  nos individus (soient les lignes de la matrice).

Les variables (attributs) choisis pour mener Ã  bien la classification
sont :

-   Gene\_ID depuis Gene
-   FD\_ID depuis Functional\_Domain
-   Length depuis Functional\_Domain
-   S\_Start et S\_End et Score depuis Conserved\_Domain
-   Family\_Link depuis Functional\_Domain

Dans un premier temps, il sera nÃ©cessaire de crÃ©er une base de donnÃ©es
MariaDB contenant la totalitÃ© de nos tables. La crÃ©ation des tables Ã 
lâ€™aide de requÃªtes est automatisÃ©e grÃ¢ce Ã  lâ€™utilisation du document
â€œcreate.and.populate.fouille.db.sqlâ€ fourni contenant la totalitÃ© des
requÃªtes.

Une fois cette Ã©tape rÃ©alisÃ©e, il faut crÃ©er une connexion Ã  MariaDB
depuis le document R Ã  lâ€™aide des informations de connexion et de
lâ€™adresse IP de la machine utilisÃ©e :

+--------------------------------------------------------------------------+
| dbh=dbConnect(MySQL(),\                                                  |
|  Â  Â  Â  Â  Â  user="guest", \                                               |
|  Â  Â  Â  Â  Â  password="bioinfo",\                                          |
|  Â  Â  Â  Â  Â  dbname="fouille", \                                           |
|  Â  Â  Â  Â  Â  host="195.220.42.4")                                          |
+--------------------------------------------------------------------------+

La premiÃ¨re requÃªte permet de rÃ©cupÃ©rer la majoritÃ© des colonnes de
notre matrice :

+--------------------------------------------------------------------------+
| query = "SELECTÂ Gene.GENE\_ID, Functional\_Domain.FD\_length,            |
| Functional\_Domain.FD\_ID, Conserved\_Domain.e\_Value\                   |
|  Â  Â  Â  Â  Â  FROMÂ Functional\_Domain, Conserved\_Domain, Gene\             |
|  Â  Â  Â  Â  Â  WHEREÂ Functional\_Domain.FD\_ID = Conserved\_Domain.FD\_ID \  |
|  Â  Â  Â  Â  Â  ANDÂ Conserved\_Domain.GENE\_ID = Gene.GENE\_ID\               |
|  Â  Â  Â  Â  Â  ANDÂ Gene.FunctionÂ likeÂ 'ABC%'\                                |
|  Â  Â  Â  Â  Â  ANDÂ Conserved\_Domain.e\_Value \< 0.005"                      |
+--------------------------------------------------------------------------+

La sÃ©lection indique que sont rÃ©cupÃ©rÃ©es :

-   Le Gene\_ID depuis la table Gene (soit lâ€™identifiant unique qui
    permet de rendre unique chaque individu de la matrice) mais
    Ã©galement de croiser les tables : câ€™est la clÃ© primaire et
    secondaire.
-   Length depuis la table Functional\_Domain (soit la longueur du
    domaine fonctionnel)
-   Le FD\_ID (identifiant unique du domaine fonctionnel retrouvÃ©)
-   La e-value depuis Conserved\_Domain qui permettra de filtrer les
    doublons

Les tables GeneÂ et Conserved\_Domain se croisent grÃ¢ce au GENE\_ID,
Conserved\_Domain et Functional\_Domain grÃ¢ce au FD\_ID. Un premier
filtre est effectuÃ© sur les e\_value \< 0.005 pour optimiser les
requÃªtes, et dans Gene : le gÃ¨ne qui doit coder pour une protÃ©ine
fonctionnelle ABC.

Il est important de retirer les doublons afin que lâ€™analyse soit menÃ©e
avec des individus uniques mais Ã©galement afin de faciliter la commande
merge qui suivra plus tard.

+--------------------------------------------------------------------------+
| The\_table1Â \<- df2Â %\>%Â group\_by(GENE\_ID)Â  %\>%Â filter(e\_Value ==    |
| min(e\_Value))                                                           |
+--------------------------------------------------------------------------+

The\_table1 reÃ§oit notre premiÃ¨re table (df2) rangÃ©e par GENE\_ID qui
seront filtrÃ©s : si des doublons de GENE\_ID sont prÃ©sents, seul
lâ€™individu ayant la e\_value la plus faible sera conservÃ© dans la
matrice afin de garder les rÃ©sultats les plus significatifs possibles.

Dans un second temps, il faut rÃ©cupÃ©rer le score normalisÃ© Ã©galement
sÃ©lectionnÃ© pour cette analyse. La table Orthology Ã©tant trÃ¨s lourde
(plusieurs millions dâ€™individus), il est important de filtrer les
rÃ©sultats dans un but dâ€™efficience du script.

+--------------------------------------------------------------------------+
| query = "SELECTÂ subject\_id, norm\_Score\                                |
|  Â  Â  Â  Â  Â FROMÂ  Orthology\                                               |
|  Â  Â  Â  Â  Â WHEREÂ evalue \<= 0.00005Â ANDÂ subject\_id INÂ (SELECTÂ Gene\_ID \ |
|  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â FROMÂ Protein \         |
|  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â WHEREÂ TypeÂ = 'ABC')"   |
+--------------------------------------------------------------------------+

Cette requÃªte permet une sÃ©lection du subject\_id (Ã©quivalent au
GENE\_ID donc qui nous permettra le lien entre les deux tables) et du
score\_norm d'intÃ©rÃªt pour notre analyse. Les filtres sâ€™effectueront via
une e-value stringeante et des types de protÃ©ines uniquement ABC.

+--------------------------------------------------------------------------+
| The\_table2 \<- dft %\>% group\_by(subject\_id) Â %\>% filter(norm\_Score |
| == max(norm\_Score))\                                                    |
| \                                                                        |
| colnames(The\_table2)[1] \<- "GENE\_ID"                                  |
+--------------------------------------------------------------------------+

LÃ  encore, il est nÃ©cessaire de retirer les doublons, mais cette fois en
ne gardant que les individus dont le score normalisÃ© sera le plus grand.

Enfin, la colonne subject\_id sera renommÃ©e en GENE\_ID afin de
faciliter la requÃªte du merge entre nos deux tables.

+--------------------------------------------------------------------------+
| table = Â merge(The\_table1, The\_table2, by = "GENE\_ID", all.x = TRUE,  |
| all.y = FALSE)                                                           |
|                                                                          |
| matrice = na.omit(table)                                                 |
|                                                                          |
| matrice1Â \<- matrice1[,-4:-5]                                            |
+--------------------------------------------------------------------------+

Le merge permet de fusionner nos deux tables sur la base du GENE\_ID
seulement pour les individus prÃ©sents dans la premiÃ¨re table
(The\_table1). La seconde requÃªte par le na.omit permet de retirer les
lignes contenant des donnÃ©es NA (not available).

Nous retirons alors les colonnes correspondant Ã  la e\_value et au
norm\_score qui nous ont permis d' amÃ©liorer la qualitÃ© du filtrage mais
ne figureront pas dans lâ€™analyse KNIME.

+--------------------------------------------------------------------------+
| conserved \<- conserved[,-1]\                                            |
| conserved \<- conserved[,-2:-4]\                                         |
| conserved \<- conserved[,-4:-5]\                                         |
| \                                                                        |
| colnames(conserved)[1] \<- "GENE\_ID"                                    |
|                                                                          |
| matrice2 = Â merge(matrice1, conserved, by = "GENE\_ID", all.x = TRUE,    |
| all.y = FALSE)                                                           |
+--------------------------------------------------------------------------+

Nous sÃ©lectionnons ensuite depuis la table conserved\_domain les
positions start et end et le score des sÃ©quences ainsi que leur Gene\_ID
renommÃ© en Gene\_ID. Le merge permettra dâ€™ajouter Ã  nos sÃ©quences
sÃ©lectionnÃ©es qui codent pour les protÃ©ines de type ABC leur sÃ©quences
start et end, ainsi que le score.

+--------------------------------------------------------------------------+
| functional\_domains \<- functional\_domains[,-2:-5]\                     |
| functional \<- functional\_domains %\>% group\_by(FD\_ID) Â %\>%          |
| filter(Family\_Link !="")\                                               |
| matriceFinal = merge(matrice2, functional, by = "FD\_ID")                |
+--------------------------------------------------------------------------+

Depuis functional\_domains, nous sÃ©lectionnons les sous-types de
familles ABC, soit la colonne Family\_link qui nous permettra de
construire nos modÃ¨les de classifications. Un filtre est effectuÃ© afin
de supprimer les lignes contenant des cases vides (une majoritÃ© de la
table). Le merge est alors effectuÃ© avec la prÃ©cÃ©dente matrice retenue.

+--------------------------------------------------------------------------+
| matriceFinal \<- matriceFinal %\>% group\_by(GENE\_ID)\                  |
| matriceFinal \<- matriceFinal[,-1]\                                      |
| write.table(matriceFinal, file="mymatrix.txt", row.names=FALSE,          |
| col.names=TRUE, sep = '\\t', append = FALSE, quote = FALSE)              |
+--------------------------------------------------------------------------+

Les derniÃ¨res Ã©tapes consistent en :

-   la vÃ©rification de lâ€™absence de doublons
-   la suppression de la colonne GENE\_ID qui ne sera plus utile Ã 
    lâ€™analyse
-   lâ€™Ã©criture de la matrice dans un fichier de sortie

Nous obtenons alors la matrice suivante, composÃ©e de 4523 individus :

![](images/image1.png)

-   Knime

Nous allons maintenant utiliser des mÃ©thodes d'apprentissage proposÃ©es
par le logiciel KNIME, un logiciel open source permettant la
construction de workflow prÃ©cis. Le workflow sera constituÃ© des
diffÃ©rentes Ã©tapes nÃ©cessaires Ã  sa rÃ©alisation depuis les lecture et
paramÃ©trage des donnÃ©es, Ã  lâ€™analyse et la visualisation des rÃ©sultats

KNIME propose lâ€™utilisation dâ€™un nombre Ã©tendu de tests statistiques et
algorithmes dÃ©diÃ©s Ã  la fouilles de donnÃ©es, nous en utiliserons
plusieurs afin dâ€™interprÃ©ter, mais Ã©galement de comparer Â les rÃ©sultats
obtenus avec plusieurs mÃ©thodes.

#### Construction du modÃ¨le {#h.j6ga06u5oijw .c69}

#### ParmiÂ les diffÃ©rents types de classificateurs, les tests ont Ã©tÃ© effectuÃ©s sur lâ€™arbre de dÃ©cision (Decision Tree Learner) et le classificateur bayÃ©sien naÃ¯f (NaÃ¯ve Bayes Classifier). {#h.y2zknj91c4sw .c69}

1.  Decision Tree Learner

La gÃ©nÃ©ration de lâ€™arbre nÃ©cessaire Ã  la classification se fait en deux
Ã©tapes :

-   Construction : initialement, les exemples du jeu d'apprentissage se
    situent Ã  la racine, puis sâ€™effectue une partition rÃ©cursive des
    exemples en sÃ©lectionnant les attributs.
-   Ã‰lagage permettant dâ€™identifier supprimer des branches correspondant
    Ã  des exceptions ou du bruit.

Une mesure de qualitÃ© intÃ©ressante est le coefficient de Gini. En effet,
cette mesure statistique permet dâ€™Ã©tablir la rÃ©partition d'une variable
au sein d'une population. Autrement dit, il mesure la dispersion dâ€™une
distribution dans la population.

Un piÃ¨ge Ã  Ã©viter dans cette modÃ©lisation est lâ€™overfitting ; une
sur-modÃ©lisation du jeu dâ€™apprentissage dont lâ€™arbre gÃ©nÃ©rÃ© risque de
trop reflÃ©ter le jeu dâ€™apprentissage. Pour y remÃ©dier, une mÃ©thode
permet d'Ã©valuer les sous-arbres Ã  Ã©laguer (pruning) : le principe
MDLÂ (minimum description length).

2.  Classificateur bayÃ©sien naÃ¯f

Nous sommes dans le cas dâ€™un apprentissage et dâ€™une prÃ©diction
probabiliste. Le terme naÃ¯f signifie que les descripteurs sont
conditionnellement indÃ©pendants.

La mÃ©thode se construit de la faÃ§on suivante :

-   DÃ©termination dâ€™un ensemble dâ€™apprentissage
-   DÃ©termination des probabilitÃ©s Ã  priori de chaque classe (donnÃ©es
    dâ€™observation)
-   Application du thÃ©orÃ¨me de Bayes ğ‘ƒ(C/ğ‘‹)=(ğ‘ƒ(ğ‘‹/C)âˆ—ğ‘ƒ(C))/ğ‘ƒ(ğ‘‹)Â afin
    dâ€™obtenir la probabilitÃ© Ã  posteriori des classes

-   Choix de la classe la plus probable

Le workflow se construit selon le modÃ¨le suivant pour les 2 types de
classification :

-   Le nÅ“ud File ReaderÂ permet le chargement des donnÃ©es. On sâ€™assure de
    configurer correctement les types de nos attributs, en particulier
    FD\_ID en tant que StringÂ et non Integer.
-   Le nÅ“ud Decision Tree LearnerÂ ou Naive Bayes LearnerÂ est configurÃ©
    de telle sorte que la colonne de classification corresponde Ã 
    Family\_Link.

#### Evaluation dâ€™un classificateur : performances\
\
Si une classe est peu prÃ©sente dans le jeu de donnÃ©es initial, le partitionnement peut entraÃ®ner la crÃ©ation dâ€™un jeu dâ€™apprentissage et dâ€™un jeu de test dont le nombre de classes sera diffÃ©rent. Pour y remÃ©dier, on utilisera des validations croisÃ©es. {#h.g89w1530ry8u .c69}

Ces validations croisÃ©es sont intÃ©grÃ©es dans Knime (â€Cross Validationâ€).
La construction s'effectue de la maniÃ¨re suivante :

-   Le nÅ“ud X-Partitioner est placÃ© entre le File Reader et le Learner.
    Son rÃ´le est de diviser le jeu de donnÃ©es en jeu dâ€™apprentissage
    pour le Learner et en jeu de test pour le Predictor. Nous avons
    testÃ© diffÃ©rents nombre de validations, les rÃ©sultats suivants pour
    toutes les mÃ©thodes dâ€™Ã©chantillonnages auront des 10 et 50 Cross
    Validation.
-   Le nÅ“ud X-Aggregator situÃ© aprÃ¨s le Predictor permet une
    confrontation de la classe permet une confrontation de la classe
    prÃ©dite Ã  la classe connue pour chacun des objets testÃ©s.
-   en fin de Workflow, le noeud Statistics affiche le taux dâ€™erreur
    moyen de notre modÃ¨le tandis que le noeud Scorer nous apporte des
    informations complÃ©mentaires tel que le nombre de VP, FP, VN, FN et
    ainsi la spÃ©cificitÃ© (capacitÃ© Ã  ne dÃ©tecter que des vrais positifs)
    et la sensibilitÃ© (capacitÃ© Ã  dÃ©tecter un maximum de vrais
    positifs).

La validation croisÃ©e â€œLeave-one-outâ€ (validation croisÃ©e avec k=s oÃ¹ k
reprÃ©sente le nombre de partitions) nâ€™a pas Ã©tÃ© effectuÃ©e car les temps
de calculs Ã©taient trop importants, cela est liÃ© Ã  la taille consÃ©quente
de la matrice individu x variable.

-   RÃ‰SULTATS

![](images/image8.png)

Fig 4 : KNIME workflowÂ for DecisionÂ Tree model.

Les rÃ©sultats obtenus pour lâ€™arbre de dÃ©cision sont reprÃ©sentÃ©s dans le
tableau ci-dessous :

Sampling method

Number of validations

Parameters

Mean percentage error

Linear sampling

10

Gain ratio / No pruning

6.520 %

Gain ratio / MDL

6.476 %

Gini index / No pruning

6.507 %

Gini index / MDL

6.485 %

50

Gain ratio / No pruning

2.985 %

Gain ratio / MDL

3.31 %

Gini index / No pruning

3.034 %

Gini index / MDL

3.311 %

Sampling method

Number of validations

Parameters

Mean percentage error

Random sampling

10

Gain ratio / No pruning

0.720 %

Gain ratio / MDL

0.815 %

Gini index / No pruning

0.703 %

Gini index / MDL

0.762 %

50

Gain ratio / No pruning

0.68 %

Gain ratio / MDL

0.71 %

Gini index / No pruning

0.687 %

Gini index / MDL

0.738 %

Sampling method

Number of validations

Parameters

Mean percentage error

Stratified sampling

10

Gain ratio / No pruning

0.687 %

Gain ratio / MDL

0.762 %

Gini index / No pruning

0.676 %

Gini index / MDL

0.747 %

50

Gain ratio / No pruning

0.665Â %

Gain ratio / MDL

0.696 %

Gini index / No pruning

0.676 %

Gini index / MDL

0.705 %

![](images/image5.png)

Fig 5 : KNIME workflowÂ for NaÃ¯ve Bayes model.

Les rÃ©sultats obtenus pour classification naÃ¯veÂ bayÃ©sienne sont
reprÃ©sentÃ©s dans le tableau ci-dessous :

Sampling method

Number of validations

Mean percentage error

Linear sampling

10

13.098 %

50

5.402 %

Sampling method

Number of validations

Mean percentage error

Random sampling

10

1.316 %

50

1.312 %

Sampling method

Number of validations

Mean percentage error

Stratified sampling

10

1.314 %

50

1.309 %

-   DISCUSSION

Lâ€™ensemble des rÃ©sultats est satisfaisant. Lâ€™arbre de dÃ©cision et le
classificateur bayÃ©sien semblent Ãªtre des types de classification
pertinent pour notre jeu de donnÃ©es. En effet, hormis pour le linear
sampling, le taux dâ€™erreur de ces deux types de classification est
infÃ©rieur Ã  2% peu importe les paramÃ¨tres sÃ©lectionnÃ©s.

Plusieurs observations :

-   Le random et stratified sampling permettent dâ€™obtenir un taux
    dâ€™erreur moyen bien infÃ©rieur Ã  celui obtenu Ã  lâ€™aide dâ€™un linear
    sampling.
-   Plus le nombre de validations est Ã©levÃ©, plus la performance du
    modÃ¨le est grande.
-   Au niveau des paramÃ¨tres, on ne peut pas dÃ©terminer lâ€™influence du
    coefficient de Gini sur le taux dâ€™erreur. Toutefois, on peut
    remarquer que les arbres nâ€™ayant pas subi dâ€™Ã©lagage ont un taux
    dâ€™erreur plus faible.

Le taux dâ€™erreur moyen le plus faible est obtenu lorsquâ€™on utilise un
arbre de dÃ©cision avec un stratified sampling, 50 validations croisÃ©es,
gain ratio et no pruning. Le taux dâ€™erreur moyen est alors deÂ 0.665 %.

Afin dâ€™effectuer une classification sur notre jeu de donnÃ©es, lâ€™arbre de
dÃ©cision semble Ãªtre une mÃ©thode plus judicieuse que le classificateur
bayÃ©sien.

Cela est probablement liÃ© au fait que ce dernier est basÃ© sur un
apprentissage probabiliste. Il calcule explicitement les probabilitÃ©s
des hypothÃ¨ses. On considÃ¨re une assomption naÃ¯ve qui concerne
lâ€™indÃ©pendance des attributs. Cette hypothÃ¨se dâ€™indÃ©pendance rend le
calcul possible et, en cas de vÃ©rification, conduit Ã  des
classificateurs optimaux.

Cependant, cette hypothÃ¨se dâ€™indÃ©pendance est rarement vÃ©rifiÃ©e. On
pourrait Ã©mettre lâ€™hypothÃ¨se de lâ€™existence dâ€™Ã©ventuelles corrÃ©lations
entre les attributs de notre jeu de donnÃ©es. Comment rÃ©soudre ce
problÃ¨me ? Les rÃ©seaux BayÃ©siens permettent de combiner le raisonnement
BayÃ©sien avec la relation causale entre les attributs.

Le nombre de validations croisÃ©es semble avoir un impact significatif
sur le taux dâ€™erreur (corrÃ©lation nÃ©gative entre le nombre de
validations croisÃ©es et le taux dâ€™erreur). Cela est liÃ© au fait que le
jeu de donnÃ©es est divisÃ© en un nombre plus important de partitions,
augmentant ainsi la taille du jeu dâ€™apprentissage; un nombre de
validation croisÃ©es de 50 permet donc dâ€™obtenir une plus grande
prÃ©cision mais augmente les temps de calcul.

Lâ€™Ã©lagage (MDL) a pour but dâ€™augmenter la prÃ©cision pour Ã©viter que
lâ€™arbre gÃ©nÃ©rÃ© ne reflÃ¨te trop le jeu dâ€™apprentissage en supprimant les
branches pouvant reprÃ©senter des anomalies. NÃ©anmoins, on observe un
taux dâ€™erreur plus grand en prÃ©sence dâ€™Ã©lagage. Ceci peut sembler
paradoxal Ã  premiÃ¨re vue, on pourrait Ã©mettre lâ€™hypothÃ¨se que lâ€™Ã©lagage
supprime des branches nÃ©cessaires Ã  la classification. Lâ€™Ã©lagage
pourrait donc Ãªtre intÃ©ressant pour un jeu de donnÃ©es de taille
considÃ©rable mais nâ€™est pas adaptÃ© pour le nÃ´tre.

-   BILAN ET PERSPECTIVES

La majoritÃ© du travail sâ€™est concentrÃ©e sur la construction de la
matrice individus-variables. Il a fallu prÃ©alablement sÃ©lectionner des
attributs pertinents biologiquement afin de classer les gÃ¨nes selon leur
sous-type de protÃ©ine ABC.

Il nous a semblÃ© logique de sÃ©lectionner les identifiants des domaines
(â€œFD\_IDâ€) pour rÃ©ussir Ã  classer les gÃ¨nes selon les sous-types de
protÃ©ines pour lesquelles ils codent, supposant que les types de
domaines fonctionnels prÃ©sents pourraient discriminer les classes.

AprÃ¨s quelques recherches bibliographiques, il nous paraissait judicieux
de sÃ©lectionner les tailles des domaines et les positions END et START :
un mÃªme domaine pourrait Ãªtre positionnÃ© Ã  des endroits diffÃ©rents chez
des protÃ©ines de deux sous-types diffÃ©rents.

Enfin, il Ã©tait nÃ©cessaire de sÃ©lectionner les noms des sous-types
protÃ©iques (â€œFamily\_linkâ€), attribut qui permet lâ€™apprentissage et
Ã©galement la classification recherchÃ©e.

Lâ€™ajout du score sâ€™est fait tardivement dans le processus de
construction de la matrice et a permis dâ€™amÃ©liorer les rÃ©sultats de
prÃ©diction.

La prÃ©sence de doublons dans les tables et de valeurs manquantes a rendu
la construction des premiÃ¨res matrices ardues, une maÃ®trise et une
comprÃ©hension forte des donnÃ©es permet alors un exercice plus aisÃ© et
plus efficace. Lâ€™utilisation de la fonction mergeÂ a prÃ©sentÃ©Â certaines
difficultÃ©s dans la prise en main des choix des arguments optionnels et
lâ€™utilisation de table trÃ¨s diffÃ©rentes (en taille, en doublons, en
attributsâ€¦).

Les rÃ©sultats issus de la classification utilisant lâ€™arbre de dÃ©cision
avec une mÃ©thode Stratified sampling ou Random sampling sont excellents
avec un pourcentage d'erreurs moyen infÃ©rieurs Ã  1%. Ces rÃ©sultats sont
significatifs et permettent de conclure quant Ã  la pertinence des
attributs choisis. Ainsi, les gÃ¨nes codent pour des protÃ©ines ABC et
peuvent Ãªtre classifiÃ©s selon leurs domaines fonctionnels, la taille et
la position de la sÃ©quence.

Il aurait cependant Ã©tÃ© intÃ©ressant dâ€™utiliser dâ€™autres mÃ©thodes de
classification en vue de comparer leurs performances avec les mÃ©thodes
abordÃ©es dans ce projet.

Ã‰ventuellement, nous aurions pu tester la validation croisÃ©e oÃ¹ k=s
(Leave-one-out). NÃ©anmoins, cette derniÃ¨re est nettement plus coÃ»teuse
en calcul que la K validation croisÃ©e sans Ãªtre nÃ©cessairement
meilleure. De plus, il existe une sous-estimation de lâ€™erreur en cas de
sur-apprentissage.

Il pourrait Ã©galement Ãªtre intÃ©ressant de tester les mÃªmes arbres avec
un plus grand nombre de cross validation, 100 par exemple, et dâ€™observer
une Ã©ventuelle amÃ©lioration des rÃ©sultats.

-   GESTION DE PROJET

La gestion de ce projet fut dÃ©terminÃ©e dÃ©but fÃ©vrier selon le diagramme
de GANTT suivant :

Lâ€™apprÃ©hension du sujet et la prise en main des tables fut plus longue
que prÃ©vue, les donnÃ©es fournies Ã©tant trÃ¨s nombreuses et le nombre
dâ€™individus trÃ¨s variÃ©s entre les tables, Hugo prit donc de lâ€™avance sur
la rÃ©daction de lâ€™introduction et du contexte.
![](images/image2.png)![](images/image6.png)

Le choix du sujet sâ€™est fait rapidement aprÃ¨s, mais le choix des
attributs et des tables Ã©taient plus arbitraires dans un premier temps,
il Ã©tait Ã©vident que la matrice serait rÃ©visÃ©e au fur et Ã  mesure des
essais sur KNIME.

Nous avons choisis de travailler nos matrices Ã  lâ€™aide de requÃªtes SQL
avec MariaDB, seulement, lâ€™accessibilitÃ© Ã  notre base de donnÃ©es et au
logiciel nous a Ã©tÃ© possible uniquement depuis la P0 sur le campus. La
semaine de vacances fin fÃ©vrier nous a permis de rattraper notre retard,
mais Ã©galement de prendre de lâ€™avance sur la construction de la premiÃ¨re
matrice. Les requÃªtes SQL Ã©taient simples Ã  rÃ©aliser, notre formation
Ã©tant solide et rÃ©cente dans ce domaine. La difficultÃ© principale que
nous avons rencontrÃ© concerne les diffÃ©rentes maniÃ¨res de merger nos
matrices (prÃ©sence de doublons).

Les retours sur la matrice nous ont pris la majoritÃ© du temps dÃ©diÃ© Ã  ce
projet : afin de gagner en efficacitÃ©, un premier binÃ´me rÃ©visait les
matrices pendant que lâ€™autre la lanÃ§ait sur KNIME et analysait les
rÃ©sultats. MalgrÃ© une organisation se voulant la plus efficace possible,
les retours sur la matrice jusquâ€™Ã  donner des rÃ©sultats acceptables nous
ont pris plus de 70% du temps accordÃ© au projet.

La rÃ©daction du projet sâ€™est maintenue tout au long du travail ce qui
nous a permis de gagner du temps sur la fin du projet.



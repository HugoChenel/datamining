# Identification et Classification de syst√®mes  ABC

## Dans le cadre de l‚ÄôUE ‚ÄúFouille de donn√©es‚Äù par R. Barriot 


![img](https://upload.wikimedia.org/wikipedia/fr/a/a4/Logo_UT3.jpg)


**CHENEL Hugo** -
**GHEZIEL Nadine**



_M1 ‚ÄúBiologie Informatique et Biologie des Syst√®mes‚Äù_


### ‚ùñ INTRODUCTION

```
‚û¢ Contexte
‚û¢ Objectifs du projet
‚û¢ Informations disponibles
```
### ‚ùñ ANALYSE

```
‚û¢ Donn√©es fournies
‚û¢ Tables
‚ñ† Taxonomy, Strain and Chromosome
‚ñ† Gene
‚ñ† Conserved_Domain and Functional_Domain
‚ñ† Orthology
‚ñ† Protein and Assembly
```
### ‚ùñ CONCEPTION

```
‚û¢ Matrice individus-variables
‚û¢ Knime
```
### ‚ùñ R√âALISATION, INTERPR√âTATION ET DISCUSSION

### ‚ùñ BILAN ET PERSPECTIVES

```
‚û¢ Gestion du projet
```


### ‚ùè CONTEXTE

 	 	
L‚Äôobjectif de ce projet consiste en la mise en place d‚Äôune m√©thode permettant l‚Äôannotation de g√©nomes complets de procaryotes en termes de syst√®mes ABC.

Les syst√®mes ABC (ATP Binding Cassette) constituent un large ensemble de prot√©ines transmembranaires. Leur r√¥le est de transporter unidirectionnellement divers substrats √† travers la membrane cytoplasmique. L‚Äôhydrolyse de l‚ÄôATP est n√©cessaire comme source d‚Äô√©nergie pour le transport. La lib√©ration d‚Äôun groupement phosphate et d‚ÄôADP est g√©n√©r√©e: il s‚Äôagit d‚Äôun transport actif primaire.

Ces syst√®mes formant une tr√®s grande famille multig√©nique sont retrouv√©s dans les 3 r√®gnes du vivant (eucaryotes, arch√©es et procaryotes). Chez ces derniers, ils sont la plupart du temps impliqu√©s dans l'efflux de mol√©cules toxiques comme les antibiotiques.

L‚Äôarchitecture des transporteurs est conserv√©e au sein de la majorit√© de ces syst√®mes. Cependant, leur organisation en domaine est variable. On observe g√©n√©ralement 2 domaines pour les exportateurs et 3 domaines pour les importeurs :

- MSD : Membrane Spanning Domain. 2 domaines MSD (h√©t√©ro ou homo-dim√®re) forment le pore √† travers la membrane.

- NBD : Nucleotide Binding Domain. 2 domaines (h√©t√©ro ou homo-dim√®re) fournissent l‚Äô√©nergie pour le transport actif par hydrolyse de l‚ÄôATP.

- SBP : Solute Binding Protein. 1 domaine capture le substrat et l‚Äôam√®ne √† l‚Äôentr√©e du pore.

De plus, certains domaines peuvent √™tre port√©s par un m√™me g√®ne ou des g√®nes diff√©rents, mais on peut √©galement retrouver un seul g√®ne pour plusieurs domaines.


![alt_text](rapport/transporteurs.png)


Fig.1 : Architecture des transporteurs ABC 
http://silico.biotoul.fr/enseignement/m1/datamining/projet/sujet.html

Par exemple : 



*   MSD-MSD : un g√®ne contient 2 domaines MSD
*   MSD-NBD : un g√®ne arbore un domaine MSD suivi d‚Äôun domaine NBD

De plus, la structure peut √™tre homodim√©rique (2 prot√©ines cod√©es par le m√™me g√®ne) ou h√©t√©rodim√©rique (2 prot√©ines cod√©es par 2 g√®nes diff√©rents). 	

Ces syst√®mes √©tant tr√®s anciens, ils se sont fortement diversifi√©s au cours de l‚Äô√©volution avec l‚Äôaccumulation de mutations sur la s√©quence de leurs g√®nes. A la suite d‚Äôanalyses de similarit√© de s√©quence, il a √©t√© possible de les classer en une vingtaine de sous-familles d√©termin√©es. Cette similarit√© de s√©quence indique que les mol√©cules transport√©es sont similaires (cela n‚Äôest pas transposable √† toutes les familles multig√©niques). Une seule mutation peut suffire √† modifier compl√®tement la fonction.

Les techniques de s√©quen√ßage g√©nomique ont progress√© ces derni√®res ann√©es, permettant d‚Äôobtenir les s√©quences g√©nomiques compl√®tes de diff√©rents organismes. La g√©nomique produit des volumes cons√©quents de donn√©es.                              

L‚Äôannotation des g√©nomes permet de trier et organiser ces donn√©es afin de leur donner du sens. Il pourrait √™tre judicieux d‚Äôutiliser les donn√©es disponibles relatives aux syst√®mes ABC afin d‚Äôannoter automatiquement les informations li√©es aux syst√®mes ABC d‚Äôun g√©nome.



### ‚ùè OBJECTIFS

Le data mining, ou Knowledge Discovery in Databases (KDD), est un processus permettant l‚Äôextraction des connaissances int√©ressantes ou des motifs/patterns √† partir d‚Äôune grande quantit√© de donn√©es. Composante essentielle des techniques d'analyse des grands jeux de donn√©es, cette technique permet l‚Äôexploration et l‚Äôanalyse de donn√©es volumineuses, la transformation de ces donn√©es en information utile, et √©ventuellement la recherche de relation entre les donn√©es.

En d‚Äôautres termes, le data mining consiste en la d√©couverte de connaissances dans les bases de donn√©es.

![img](https://touriaelouahabi.files.wordpress.com/2013/04/sans-titre.png)

Fig. 2 : Processus d‚Äôextraction de connaissances √† partir de bases de donn√©es
https://touriaelouahabi.wordpress.com/ecbd/concepts-et-principes-du-data-mining/

Une succession d‚Äô√©tapes est impliqu√©e dans le processus de d√©couverte de connaissances:



*   s√©lection des donn√©es √† l‚Äôaide de la cr√©ation du jeu de donn√©es cible (int√©gration)
*   nettoyage et pr√©traitement des donn√©es
*   r√©duction et transformation des donn√©es (normalisation)
*   choix des fonctionnalit√©s  de data mining et des algorithmes 
*   recherche de motifs int√©ressants
*   repr√©sentation de connaissances apr√®s √©valuation de ces motifs

Cette proc√©dure aboutit √† la d√©couverte de connaissances.

Deux types d'apprentissages sont utilis√©s en fouille de donn√©es : 

-Le premier est un apprentissage non supervis√©, les classes sont alors inconnues. L‚Äôobjectif est de, √† partir de n observations, constituer k groupes tels que ces groupes soient constitu√©s d‚Äôobservations semblables, mais qu‚Äôils soient le plus diff√©rents possibles entre eux.  On parle de clustering.
Il existe des m√©thodes non hi√©rarchiques, dites par partitionnement, qui consiste en la construction de k partitions qui seront corrig√©es jusqu‚Äô√† obtenir une similarit√© parfaite. L‚Äôexemple le plus connu est la m√©thode du k-means.
Les m√©thodes hi√©rarchiques consistent en la cr√©ation d‚Äôune d√©composition hi√©rarchique par agglom√©ration ou division de groupes similaires ou dissimilaires(ex : Hierarchical clustering).

-Le second est un apprentissage supervis√© : √©tant donn√© un ensemble de classes connues, √©tablir les ¬´ meilleures ¬ª r√®gles de classement, le jeu de donn√©es d‚Äôapprentissage fournit donc les classes des objets. Ce type d‚Äôapprentissage correspond √† la classification.
L‚Äôobjectif de cet apprentissage est de mod√©liser la relation entre les observations et la classe d‚Äôappartenance, mais √©galement d‚Äôidentifier la classe d‚Äôappartenance d‚Äôun objet √† partir d‚Äôun ensemble de descripteurs. De nombreux outils existent, tels que la m√©thode des K plus proches voisins, ou celle de l‚Äôarbre de d√©cision. 

Les arbres de d√©cisions sont des outils d‚Äôaide √† la d√©cision :  une proc√©dure de classification est construite suivant un protocole simple tout en offrant une interpr√©tabilit√© agr√©able aux utilisateurs. Les variables discriminantes seront choisies par le logiciel selon une suite de calculs statistiques. 

La m√©thode des K plus proches voisins (ou knn pour ‚Äúk-nearest neighbors‚Äù) se base sur un algorithme dit paresseux : il n‚Äôapprend rien pendant la phase d‚Äôentra√Ænement. La pr√©diction d‚Äôune classe se base sur un concept simple : l‚Äôalgorithme re√ßoit une nouvelle donn√©e et cherche √† calculer ses k plus proches voisins (selon une distance euclidienne par exemple). La donn√©e re√ßoit la m√™me classe que la classe majoritaire de ses k plus proches voisins.

Il existe plusieurs mani√®res d‚Äô√©valuer un classificateur : 

La validation crois√©e est une m√©thode d‚Äôestimation de la fiabilit√© d‚Äôun mod√®le bas√© sur une technique d‚Äô√©chantillonnage. Son principe consiste √† diviser les donn√©es en k-partitions puis utiliser k-1 partitions pour l‚Äôapprentissage et la derni√®re pour le test. Apr√®s l'apprentissage, on peut calculer une performance de validation.

Divers autres param√®tres permettent l‚Äô√©valuation d‚Äôun classificateur : \
-Calcul de la sp√©cificit√© : capacit√© √† ne d√©tecter que des vrais positifs \
-Calcul de la sensibilit√© : capacit√© √† d√©tecter un maximum de vrais positifs \
-Courbe ROC : graphique des performances du mod√®le, vrais positifs en fonction des faux positifs 

-AUC : pour l‚Äôaire sous la courbe ROC : entre 0 et 1, c‚Äôest une valeur qui fournit la capacit√© discriminatoire du mod√®le.

La classification est le type d‚Äôapprentissage retenu pour ce projet afin de classer les g√®nes selon leur sous-type de prot√©ine ABC. 



### ‚ùè INFORMATIONS DISPONIBLES

ABCdb est une banque de donn√©es publique d√©di√©e aux transporteurs ABC. Elle a √©t√© encod√©e √† partir de g√©nomes procaryotes int√©gralement s√©quenc√©s. On dispose donc de donn√©es sur les g√©nomes expertis√©s permettant la classification automatique.

Comment d√©finir si un g√®ne code ou pas pour un partenaire d‚Äôun syst√®me ABC ?           

Deux informations sont pertinentes parmi celles √† notre disposition :



*   les domaines pr√©sents sur la s√©quence prot√©ique correspondant au g√®ne √† partir de banques de donn√©es de domaines
*   l‚Äôorthologie de type 1:1 entre les g√®nes des g√©nomes expertis√©s sachant que l‚Äôon conna√Æt leur architecture en domaine et leur sous-famille.


### ‚ùñ ANALYSE

![img](https://lh3.googleusercontent.com/ZH4W9kpD9plihZe9fhVGjElyyYseuG4Z5FuwBHazW6Jl-rNm0iICcq21f3zg-c7WZF2ZOeop87nCmWtCgC7qPC8g94e5mITJ1QPwa0TjMezYr17zRh8tgAjAdZqBHG2WUnKSVPU9)

Fig 3 : Sch√©ma Base de donn√©es
http://silico.biotoul.fr/enseignement/m1/datamining/projet/sujet.html

Dans un premier temps, il est important de choisir les tables jug√©es pertinentes √† notre analyse. Selon une r√©flexion men√©e sur notre probl√©matique, et sur les attributs contenus dans les tables propos√©es, nous avons port√©s nos choix sur les suivantes : 



*   Gene
*   Protein
*   Conserved_Domain
*   Functional_Domain

Les tables contiennent certains attributs pertinents √† notre analyse : Gene_ID et FD_ID nous permettront de faire correspondre nos 4 tables d'int√©r√™ts.



### ‚ùñ CONCEPTION

#### ‚û¢ Matrice individus-variables

Notre matrice individus-variable a √©t√© construite √† partir du logiciel R version 3.04. Le gestionnaire de bases de donn√©es utilis√© est le serveur MariaDB version 10.5.9. L‚Äôutilisation du serveur depuis R √† l‚Äôaide de la librairie RMySQL permet d‚Äôeffectuer des liens entre ces tables gr√¢ce √† des requ√™tes SQL, et ainsi tirer des donn√©es pertinentes pour la suite de l‚Äôanalyse dans le but d‚Äôeffectuer notre classification.

Gene ID correspondent √† nos individus (soient les lignes de la matrice). 

Les variables (attributs) choisis pour mener √† bien la classification sont : 



*   Gene_ID depuis Gene
*   FD_ID depuis Functional_Domain
*   Length depuis Functional_Domain
*   S_Start et S_End et Score depuis Conserved_Domain 
*   Family_Link depuis Functional_Domain

Dans un premier temps, il sera n√©cessaire de cr√©er une base de donn√©es MariaDB contenant la totalit√© de nos tables. La cr√©ation des tables √† l‚Äôaide de requ√™tes est automatis√©e gr√¢ce √† l‚Äôutilisation du document ‚Äúcreate.and.populate.fouille.db.sql‚Äù fourni contenant la totalit√© des requ√™tes. 

Une fois cette √©tape r√©alis√©e, il faut cr√©er une connexion √† MariaDB depuis le document R √† l‚Äôaide des informations de connexion et de l‚Äôadresse IP de la machine utilis√©e :


```
dbh=dbConnect(MySQL(),
           user="guest", 
           password="bioinfo",
           dbname="fouille", 
           host="195.220.42.4")
```


La premi√®re requ√™te permet de r√©cup√©rer la majorit√© des colonnes de notre matrice :


```
query = "SELECT Gene.GENE_ID, Functional_Domain.FD_length, Functional_Domain.FD_ID, Conserved_Domain.e_Value
           FROM Functional_Domain, Conserved_Domain, Gene
           WHERE Functional_Domain.FD_ID = Conserved_Domain.FD_ID 
           AND Conserved_Domain.GENE_ID = Gene.GENE_ID
           AND Gene.Function like 'ABC%'
           AND Conserved_Domain.e_Value < 0.005"
```


La s√©lection indique que sont r√©cup√©r√©es :



*   Le Gene_ID depuis la table Gene (soit l‚Äôidentifiant unique qui permet de rendre unique chaque individu de la matrice) mais √©galement de croiser les tables : c‚Äôest la cl√© primaire et secondaire. 
*   Length depuis la table Functional_Domain (soit la longueur du domaine fonctionnel) 
*   Le FD_ID (identifiant unique du domaine fonctionnel retrouv√©) 
*   La e-value depuis Conserved_Domain qui permettra de filtrer les doublons 

Les tables Gene et Conserved_Domain se croisent gr√¢ce au GENE_ID, Conserved_Domain et Functional_Domain gr√¢ce au FD_ID. Un premier filtre est effectu√© sur les e_value &lt; 0.005 pour optimiser les requ√™tes, et dans Gene : le g√®ne qui doit coder pour une prot√©ine fonctionnelle ABC.

Il est important de retirer les doublons afin que l‚Äôanalyse soit men√©e avec des individus uniques mais √©galement afin de faciliter la commande merge qui suivra plus tard. 


```
The_table1 <- df2 %>% group_by(GENE_ID)  %>% filter(e_Value == min(e_Value))
```


The_table1 re√ßoit notre premi√®re table (df2) rang√©e par GENE_ID qui seront filtr√©s : si des doublons de GENE_ID sont pr√©sents, seul l‚Äôindividu ayant la e_value la plus faible sera conserv√© dans la matrice afin de garder les r√©sultats les plus significatifs possibles.

Dans un second temps, il faut r√©cup√©rer le score normalis√© √©galement s√©lectionn√© pour cette analyse. La table Orthology √©tant tr√®s lourde (plusieurs millions d‚Äôindividus), il est important de filtrer les r√©sultats dans un but d‚Äôefficience du script.


```
query = "SELECT subject_id, norm_Score
          FROM  Orthology
          WHERE evalue <= 0.00005 AND subject_id IN (SELECT Gene_ID 
                                                  FROM Protein 
                                                  WHERE Type = 'ABC')" 
```


Cette requ√™te permet une s√©lection du subject_id (√©quivalent au GENE_ID donc qui nous permettra le lien entre les deux tables) et du score_norm d'int√©r√™t pour notre analyse. Les filtres s‚Äôeffectueront via une e-value stringeante et des types de prot√©ines uniquement ABC.


```
The_table2 <- dft %>% group_by(subject_id)  %>% filter(norm_Score == max(norm_Score))

colnames(The_table2)[1] <- "GENE_ID"
```


L√† encore, il est n√©cessaire de retirer les doublons, mais cette fois en ne gardant que les individus dont le score normalis√© sera le plus grand.

Enfin, la colonne subject_id sera renomm√©e en GENE_ID afin de faciliter la requ√™te du merge entre nos deux tables.


```
table =  merge(The_table1, The_table2, by = "GENE_ID", all.x = TRUE, all.y = FALSE)

matrice = na.omit(table)

matrice1 <- matrice1[,-4:-5]
```


Le merge permet de fusionner nos deux tables sur la base du GENE_ID seulement pour les individus pr√©sents dans la premi√®re table (The_table1). La seconde requ√™te par le _na.omit _permet de retirer les lignes contenant des donn√©es NA (not available).

Nous retirons alors les colonnes correspondant √† la e_value et au norm_score qui nous ont permis d' am√©liorer la qualit√© du filtrage mais ne figureront pas dans l‚Äôanalyse KNIME.


```
conserved <- conserved[,-1]
conserved <- conserved[,-2:-4]
conserved <- conserved[,-4:-5]

colnames(conserved)[1] <- "GENE_ID"

matrice2 =  merge(matrice1, conserved, by = "GENE_ID", all.x = TRUE, all.y = FALSE)
```


Nous s√©lectionnons ensuite depuis la table conserved_domain les positions start et end et le score des s√©quences ainsi que leur Gene_ID renomm√© en Gene_ID. Le merge permettra d‚Äôajouter √† nos s√©quences s√©lectionn√©es qui codent pour les prot√©ines de type ABC leur s√©quences start et end, ainsi que le score.


```
functional_domains <- functional_domains[,-2:-5]
functional <- functional_domains %>% group_by(FD_ID)  %>% filter(Family_Link !="")
matriceFinal = merge(matrice2, functional, by = "FD_ID")
```


Depuis functional_domains, nous s√©lectionnons les sous-types de familles ABC, soit la colonne Family_link qui nous permettra de construire nos mod√®les de classifications. Un filtre est effectu√© afin de supprimer les lignes contenant des cases vides (une majorit√© de la table). Le merge est alors effectu√© avec la pr√©c√©dente matrice retenue. 


```
matriceFinal <- matriceFinal %>% group_by(GENE_ID)
matriceFinal <- matriceFinal[,-1]
write.table(matriceFinal, file="mymatrix.txt", row.names=FALSE, col.names=TRUE, sep = '\t', append = FALSE, quote = FALSE)
```


Les derni√®res √©tapes consistent en : 



*   la v√©rification de l‚Äôabsence de doublons
*   la suppression de la colonne GENE_ID qui ne sera plus utile √† l‚Äôanalyse 
*   l‚Äô√©criture de la matrice dans un fichier de sortie 

Nous obtenons alors une matrice compos√©e de 4523 individus.




#### ‚û¢ Knime

Nous allons maintenant utiliser des m√©thodes d'apprentissage propos√©es par le logiciel KNIME, un logiciel open source permettant la construction de workflow pr√©cis. Le workflow sera constitu√© des diff√©rentes √©tapes n√©cessaires √† sa r√©alisation depuis les lecture et param√©trage des donn√©es, √† l‚Äôanalyse et la visualisation des r√©sultats 

KNIME propose l‚Äôutilisation d‚Äôun nombre √©tendu de tests statistiques et algorithmes d√©di√©s √† la fouilles de donn√©es, nous en utiliserons plusieurs afin d‚Äôinterpr√©ter, mais √©galement de comparer  les r√©sultats obtenus avec plusieurs m√©thodes.


#### Construction du mod√®le


Parmi les diff√©rents types de classificateurs, les tests ont √©t√© effectu√©s sur l‚Äôarbre de d√©cision (Decision Tree Learner) et le classificateur bay√©sien na√Øf (Na√Øve Bayes Classifier).



##### 1. Decision Tree Learner

La g√©n√©ration de l‚Äôarbre n√©cessaire √† la classification se fait en deux √©tapes :



*   Construction : initialement, les exemples du jeu d'apprentissage se situent √† la racine, puis s‚Äôeffectue une partition r√©cursive des exemples en s√©lectionnant les attributs.
*   √âlagage permettant d‚Äôidentifier supprimer des branches correspondant √† des exceptions ou du bruit.

Une mesure de qualit√© int√©ressante est le coefficient de Gini. En effet, cette mesure statistique permet d‚Äô√©tablir la r√©partition d'une variable au sein d'une population. Autrement dit, il mesure la dispersion d‚Äôune distribution dans la population.

Un pi√®ge √† √©viter dans cette mod√©lisation est l‚Äôoverfitting ; une sur-mod√©lisation du jeu d‚Äôapprentissage dont l‚Äôarbre g√©n√©r√© risque de trop refl√©ter le jeu d‚Äôapprentissage. Pour y rem√©dier, une m√©thode permet d'√©valuer les sous-arbres √† √©laguer (pruning) : le principe MDL (minimum description length).



##### 2. Classificateur bay√©sien na√Øf

Nous sommes dans le cas d‚Äôun apprentissage et d‚Äôune pr√©diction probabiliste. Le terme na√Øf signifie que les descripteurs sont conditionnellement ind√©pendants.

La m√©thode se construit de la fa√ßon suivante :



*   D√©termination d‚Äôun ensemble d‚Äôapprentissage
*   D√©termination des probabilit√©s √† priori de chaque classe (donn√©es d‚Äôobservation)
*   Application du th√©or√®me de Bayes _ùëÉ_(_C_/_ùëã_)=(_ùëÉ_(_ùëã_/_C_)‚àó_ùëÉ_(_C_))/_ùëÉ(ùëã_) afin d‚Äôobtenir la probabilit√© √† posteriori des classes
*   Choix de la classe la plus probable

Le workflow se construit selon le mod√®le suivant pour les 2 types de classification :



*   Le n≈ìud _File Reader_ permet le chargement des donn√©es. On s‚Äôassure de configurer correctement les types de nos attributs, en particulier FD_ID en tant que _String_ et non _Integer_.
*   Le n≈ìud _Decision Tree Learner_ ou _Naive Bayes Learner_ est configur√© de telle sorte que la colonne de classification corresponde √† _Family_Link_.


#### Evaluation d‚Äôun classificateur : performances

Si une classe est peu pr√©sente dans le jeu de donn√©es initial, le partitionnement peut entra√Æner la cr√©ation d‚Äôun jeu d‚Äôapprentissage et d‚Äôun jeu de test dont le nombre de classes sera diff√©rent. Pour y rem√©dier, on utilisera des validations crois√©es.

Ces validations crois√©es sont int√©gr√©es dans Knime (`"Cross Validation"`). La construction s'effectue de la mani√®re suivante :



*   Le n≈ìud X-Partitioner est plac√© entre le File Reader et le Learner. Son r√¥le est de diviser le jeu de donn√©es en jeu d‚Äôapprentissage pour le Learner et en jeu de test pour le Predictor. Nous avons test√© diff√©rents nombre de validations, les r√©sultats suivants pour toutes les m√©thodes d‚Äô√©chantillonnages auront des 10 et 50 Cross Validation.
*   Le n≈ìud X-Aggregator situ√© apr√®s le Predictor permet une confrontation de la classe permet une confrontation de la classe pr√©dite √† la classe connue pour chacun des objets test√©s.
*   en fin de Workflow, le noeud Statistics affiche le taux d‚Äôerreur moyen de notre mod√®le tandis que le noeud Scorer nous apporte des informations compl√©mentaires tel que le nombre de VP, FP, VN, FN et ainsi la sp√©cificit√© (capacit√© √† ne d√©tecter que des vrais positifs) et la sensibilit√© (capacit√© √† d√©tecter un maximum de vrais positifs).

La validation crois√©e ‚ÄúLeave-one-out‚Äù (validation crois√©e avec k=s o√π k repr√©sente le nombre de partitions) n‚Äôa pas √©t√© effectu√©e car les temps de calculs √©taient trop importants, cela est li√© √† la taille cons√©quente de la matrice individu x variable.



### ‚ùñ R√âSULTATS



![img](rapport/image_DecisionTree.png)

Fig 4 : KNIME _workflow_ for Decision Tree model.

Les r√©sultats obtenus pour l‚Äôarbre de d√©cision sont repr√©sent√©s dans le tableau ci-dessous :


<table>
  <tr>
   <td><em>Sampling method</em>
   </td>
   <td><em>Number of validations</em>
   </td>
   <td><em>Parameters</em>
   </td>
   <td><em>Mean percentage error </em>
   </td>
  </tr>
  <tr>
   <td rowspan="8" ><strong>Linear sampling</strong>
   </td>
   <td rowspan="4" >10
   </td>
   <td>Gain ratio / No pruning
   </td>
   <td>6.520 %
   </td>
  </tr>
  <tr>
   <td>Gain ratio / MDL
   </td>
   <td>6.476 %
   </td>
  </tr>
  <tr>
   <td>Gini index / No pruning
   </td>
   <td>6.507 %
   </td>
  </tr>
  <tr>
   <td>Gini index / MDL
   </td>
   <td>6.485 %
   </td>
  </tr>
  <tr>
   <td rowspan="4" >50
   </td>
   <td>Gain ratio / No pruning
   </td>
   <td>2.985 %
   </td>
  </tr>
  <tr>
   <td>Gain ratio / MDL
   </td>
   <td>3.31 %
   </td>
  </tr>
  <tr>
   <td>Gini index / No pruning
   </td>
   <td>3.034 %
   </td>
  </tr>
  <tr>
   <td>Gini index / MDL
   </td>
   <td>3.311 %
   </td>
  </tr>
</table>



<table>
  <tr>
   <td><em>Sampling method</em>
   </td>
   <td><em>Number of validations</em>
   </td>
   <td><em>Parameters</em>
   </td>
   <td><em>Mean percentage error </em>
   </td>
  </tr>
  <tr>
   <td rowspan="8" ><strong>Random sampling</strong>
   </td>
   <td rowspan="4" >10
   </td>
   <td>Gain ratio / No pruning
   </td>
   <td>0.720 %
   </td>
  </tr>
  <tr>
   <td>Gain ratio / MDL
   </td>
   <td>0.815 %
   </td>
  </tr>
  <tr>
   <td>Gini index / No pruning
   </td>
   <td>0.703 %
   </td>
  </tr>
  <tr>
   <td>Gini index / MDL
   </td>
   <td>0.762 %
   </td>
  </tr>
  <tr>
   <td rowspan="4" >50
   </td>
   <td>Gain ratio / No pruning
   </td>
   <td>0.68 %
   </td>
  </tr>
  <tr>
   <td>Gain ratio / MDL
   </td>
   <td>0.71 %
   </td>
  </tr>
  <tr>
   <td>Gini index / No pruning
   </td>
   <td>0.687 %
   </td>
  </tr>
  <tr>
   <td>Gini index / MDL
   </td>
   <td>0.738 %
   </td>
  </tr>
</table>



<table>
  <tr>
   <td><em>Sampling method</em>
   </td>
   <td><em>Number of validations</em>
   </td>
   <td><em>Parameters</em>
   </td>
   <td><em>Mean percentage error </em>
   </td>
  </tr>
  <tr>
   <td rowspan="8" ><strong>Stratified sampling</strong>
   </td>
   <td rowspan="4" >10
   </td>
   <td>Gain ratio / No pruning
   </td>
   <td>0.687 %
   </td>
  </tr>
  <tr>
   <td>Gain ratio / MDL
   </td>
   <td>0.762 %
   </td>
  </tr>
  <tr>
   <td>Gini index / No pruning
   </td>
   <td>0.676 %
   </td>
  </tr>
  <tr>
   <td>Gini index / MDL
   </td>
   <td>0.747 %
   </td>
  </tr>
  <tr>
   <td rowspan="4" >50
   </td>
   <td>Gain ratio / No pruning
   </td>
   <td><span style="text-decoration:underline;">0.665</span> %
   </td>
  </tr>
  <tr>
   <td>Gain ratio / MDL
   </td>
   <td>0.696 %
   </td>
  </tr>
  <tr>
   <td>Gini index / No pruning
   </td>
   <td>0.676 %
   </td>
  </tr>
  <tr>
   <td>Gini index / MDL
   </td>
   <td>0.705 %
   </td>
  </tr>
</table>



Passons maintenant √† une autre m√©thode de classification :

![img](rapport/image_NaiveBayes.png)

Fig 5 : KNIME workflow for Na√Øve Bayes model.


Les r√©sultats obtenus pour classification _na√Øve_ bay√©sienne sont repr√©sent√©s dans le tableau ci-dessous :


<table>
  <tr>
   <td><em>Sampling method</em>
   </td>
   <td><em>Number of validations</em>
   </td>
   <td><em>Mean percentage error </em>
   </td>
  </tr>
  <tr>
   <td rowspan="2" ><strong>Linear sampling</strong>
   </td>
   <td>10
   </td>
   <td>13.098 %
   </td>
  </tr>
  <tr>
   <td>50
   </td>
   <td>5.402 %
   </td>
  </tr>
</table>



<table>
  <tr>
   <td><em>Sampling method</em>
   </td>
   <td><em>Number of validations</em>
   </td>
   <td><em>Mean percentage error </em>
   </td>
  </tr>
  <tr>
   <td rowspan="2" ><strong>Random sampling</strong>
   </td>
   <td>10
   </td>
   <td>1.316 %
   </td>
  </tr>
  <tr>
   <td>50
   </td>
   <td>1.312 %
   </td>
  </tr>
</table>



<table>
  <tr>
   <td><em>Sampling method</em>
   </td>
   <td><em>Number of validations</em>
   </td>
   <td><em>Mean percentage error </em>
   </td>
  </tr>
  <tr>
   <td rowspan="2" ><strong>Stratified sampling</strong>
   </td>
   <td>10
   </td>
   <td>1.314 %
   </td>
  </tr>
  <tr>
   <td>50
   </td>
   <td>1.309 %
   </td>
  </tr>
</table>




### ‚ùñ DISCUSSION

L‚Äôensemble des r√©sultats est satisfaisant. L‚Äôarbre de d√©cision et le classificateur bay√©sien semblent √™tre des types de classification pertinent pour notre jeu de donn√©es. En effet, hormis pour le linear sampling, le taux d‚Äôerreur de ces deux types de classification est inf√©rieur √† 2% peu importe les param√®tres s√©lectionn√©s.

Plusieurs observations :



*   Le random et stratified sampling permettent d‚Äôobtenir un taux d‚Äôerreur moyen bien inf√©rieur √† celui obtenu √† l‚Äôaide d‚Äôun linear sampling.
*   Plus le nombre de validations est √©lev√©, plus la performance du mod√®le est grande.
*   Au niveau des param√®tres, on ne peut pas d√©terminer l‚Äôinfluence du coefficient de Gini sur le taux d‚Äôerreur. Toutefois, on peut remarquer que les arbres n‚Äôayant pas subi d‚Äô√©lagage ont un taux d‚Äôerreur plus faible.

Le taux d‚Äôerreur moyen le plus faible est obtenu lorsqu‚Äôon utilise un arbre de d√©cision avec un stratified sampling, 50 validations crois√©es, gain ratio et no pruning. Le taux d‚Äôerreur moyen est alors de 0.665 %.

Afin d‚Äôeffectuer une classification sur notre jeu de donn√©es, l‚Äôarbre de d√©cision semble √™tre une m√©thode plus judicieuse que le classificateur bay√©sien.

Cela est probablement li√© au fait que ce dernier est bas√© sur un apprentissage probabiliste. Il calcule explicitement les probabilit√©s des hypoth√®ses. On consid√®re une assomption na√Øve qui concerne l‚Äôind√©pendance des attributs. Cette hypoth√®se d‚Äôind√©pendance rend le calcul possible et, en cas de v√©rification, conduit √† des classificateurs optimaux.

Cependant, cette hypoth√®se d‚Äôind√©pendance est rarement v√©rifi√©e. On pourrait √©mettre l‚Äôhypoth√®se de l‚Äôexistence d‚Äô√©ventuelles corr√©lations entre les attributs de notre jeu de donn√©es. Comment r√©soudre ce probl√®me ? Les r√©seaux Bay√©siens permettent de combiner le raisonnement Bay√©sien avec la relation causale entre les attributs.

Le nombre de validations crois√©es semble avoir un impact significatif sur le taux d‚Äôerreur (corr√©lation n√©gative entre le nombre de validations crois√©es et le taux d‚Äôerreur). Cela est li√© au fait que le jeu de donn√©es est divis√© en un nombre plus important de partitions, augmentant ainsi la taille du jeu d‚Äôapprentissage; un nombre de validation crois√©es de 50 permet donc d‚Äôobtenir une plus grande pr√©cision mais augmente les temps de calcul.

L‚Äô√©lagage (MDL) a pour but d‚Äôaugmenter la pr√©cision pour √©viter que l‚Äôarbre g√©n√©r√© ne refl√®te trop le jeu d‚Äôapprentissage en supprimant les branches pouvant repr√©senter des anomalies. N√©anmoins, on observe un taux d‚Äôerreur plus grand en pr√©sence d‚Äô√©lagage. Ceci peut sembler paradoxal √† premi√®re vue, on pourrait √©mettre l‚Äôhypoth√®se que l‚Äô√©lagage supprime des branches n√©cessaires √† la classification. L‚Äô√©lagage pourrait donc √™tre int√©ressant pour un jeu de donn√©es de taille consid√©rable mais n‚Äôest pas adapt√© pour le n√¥tre.



### ‚ùñ BILAN ET PERSPECTIVES

La majorit√© du travail s‚Äôest concentr√©e sur la construction de la matrice individus-variables. Il a fallu pr√©alablement s√©lectionner des attributs pertinents biologiquement afin de classer les g√®nes selon leur sous-type de prot√©ine ABC. 

Il nous a sembl√© logique de s√©lectionner les identifiants des domaines (‚ÄúFD_ID‚Äù) pour r√©ussir √† classer les g√®nes selon les sous-types de prot√©ines pour lesquelles ils codent, supposant que les types de domaines fonctionnels pr√©sents pourraient discriminer les classes.

Apr√®s quelques recherches bibliographiques, il nous paraissait judicieux de s√©lectionner les tailles des domaines et les positions END et START : un m√™me domaine pourrait √™tre positionn√© √† des endroits diff√©rents chez des prot√©ines de deux sous-types diff√©rents. 

Enfin, il √©tait n√©cessaire de s√©lectionner les noms des sous-types prot√©iques (‚ÄúFamily_link‚Äù), attribut qui permet l‚Äôapprentissage et √©galement la classification recherch√©e.

L‚Äôajout du score s‚Äôest fait tardivement dans le processus de construction de la matrice et a permis d‚Äôam√©liorer les r√©sultats de pr√©diction.

La pr√©sence de doublons dans les tables et de valeurs manquantes a rendu la construction des premi√®res matrices ardues, une ma√Ætrise et une compr√©hension forte des donn√©es permet alors un exercice plus ais√© et plus efficace. L‚Äôutilisation de la fonction _merge_ a pr√©sent√© certaines difficult√©s dans la prise en main des choix des arguments optionnels et l‚Äôutilisation de table tr√®s diff√©rentes (en taille, en doublons, en attributs‚Ä¶).

Les r√©sultats issus de la classification utilisant l‚Äôarbre de d√©cision avec une m√©thode Stratified sampling ou Random sampling sont excellents avec un pourcentage d'erreurs moyen inf√©rieurs √† 1%. Ces r√©sultats sont significatifs et permettent de conclure quant √† la pertinence des attributs choisis. Ainsi, les g√®nes codent pour des prot√©ines ABC et peuvent √™tre classifi√©s selon leurs domaines fonctionnels, la taille et la position de la s√©quence.

Il aurait cependant √©t√© int√©ressant d‚Äôutiliser d‚Äôautres m√©thodes de classification en vue de comparer leurs performances avec les m√©thodes abord√©es dans ce projet. 

√âventuellement, nous aurions pu tester la validation crois√©e o√π k=s (Leave-one-out). N√©anmoins, cette derni√®re est nettement plus co√ªteuse en calcul que la K validation crois√©e sans √™tre n√©cessairement meilleure. De plus, il existe une sous-estimation de l‚Äôerreur en cas de sur-apprentissage.

Il pourrait √©galement √™tre int√©ressant de tester les m√™mes arbres avec un plus grand nombre de cross validation, 100 par exemple, et d‚Äôobserver une √©ventuelle am√©lioration des r√©sultats. 



### ‚ùè GESTION DE PROJET

La gestion de ce projet fut d√©termin√©e d√©but f√©vrier selon le diagramme de GANTT suivant : 

L‚Äôappr√©hension du sujet et la prise en main des tables fut plus longue que pr√©vue, les donn√©es fournies √©tant tr√®s nombreuses et le nombre d‚Äôindividus tr√®s vari√©s entre les tables, Hugo prit donc de l‚Äôavance sur la r√©daction de l‚Äôintroduction et du contexte. 

Le choix du sujet s‚Äôest fait rapidement apr√®s, mais le choix des attributs et des tables √©taient plus arbitraires dans un premier temps, il √©tait √©vident que la matrice serait r√©vis√©e au fur et √† mesure des essais sur KNIME. 

Nous avons choisis de travailler nos matrices √† l‚Äôaide de requ√™tes SQL avec MariaDB, seulement, l‚Äôaccessibilit√© √† notre base de donn√©es et au logiciel nous a √©t√© possible uniquement depuis la P0 sur le campus. La semaine de vacances fin f√©vrier nous a permis de rattraper notre retard, mais √©galement de prendre de l‚Äôavance sur la construction de la premi√®re matrice. Les requ√™tes SQL √©taient simples √† r√©aliser, notre formation √©tant solide et r√©cente dans ce domaine. La difficult√© principale que nous avons rencontr√© concerne les diff√©rentes mani√®res de merger nos matrices (pr√©sence de doublons). 

Les retours sur la matrice nous ont pris la majorit√© du temps d√©di√© √† ce projet : afin de gagner en efficacit√©, un premier bin√¥me r√©visait les matrices pendant que l‚Äôautre la lan√ßait sur KNIME et analysait les r√©sultats. Malgr√© une organisation se voulant la plus efficace possible, les retours sur la matrice jusqu‚Äô√† donner des r√©sultats acceptables nous ont pris plus de 70% du temps accord√© au projet. 

La r√©daction du projet s‚Äôest maintenue tout au long du travail ce qui nous a permis de gagner du temps sur la fin du projet. 
